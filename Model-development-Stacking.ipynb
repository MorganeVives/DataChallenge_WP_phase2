{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87f2b96a-5b8f-49c2-bb10-d56eea7c9473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import openpyxl\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18142a1a-449c-4056-ad68-3704c86e321a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "# import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbdb953f-9b6c-402f-97a7-694ea991772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor, RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC, RidgeCV, Ridge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.svm import LinearSVR\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfbdb5cf-fddb-4c1d-8d99-5712adf34c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Functions.helper_functions import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b402172-9749-43c5-a553-c94813496dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0038d4f6-5114-412b-b438-324e4d0ccbf3",
   "metadata": {},
   "source": [
    "# Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb7ce6b3-5881-4db0-87ca-244b7161cd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wp1 = pd.read_csv('Data/Preprocessing/WP1_train_preprocessed.csv', sep=',')\n",
    "train_wp2 = pd.read_csv('Data/Preprocessing/WP2_train_preprocessed.csv', sep=',')\n",
    "train_wp3 = pd.read_csv('Data/Preprocessing/WP3_train_preprocessed.csv', sep=',')\n",
    "train_wp4 = pd.read_csv('Data/Preprocessing/WP4_train_preprocessed.csv', sep=',')\n",
    "train_wp5 = pd.read_csv('Data/Preprocessing/WP5_train_preprocessed.csv', sep=',')\n",
    "train_wp6 = pd.read_csv('Data/Preprocessing/WP6_train_preprocessed.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88839967-5d4a-4ed6-b3ad-2ed819309b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_wp1 = pd.read_csv('Data/Preprocessing/WP1_test_preprocessed.csv', sep=',')\n",
    "test_wp2 = pd.read_csv('Data/Preprocessing/WP2_test_preprocessed.csv', sep=',')\n",
    "test_wp3 = pd.read_csv('Data/Preprocessing/WP3_test_preprocessed.csv', sep=',')\n",
    "test_wp4 = pd.read_csv('Data/Preprocessing/WP4_test_preprocessed.csv', sep=',')\n",
    "test_wp5 = pd.read_csv('Data/Preprocessing/WP5_test_preprocessed.csv', sep=',')\n",
    "test_wp6 = pd.read_csv('Data/Preprocessing/WP6_test_preprocessed.csv', sep=',')\n",
    "test_dates = pd.read_csv('Data/Initial/test.csv', sep=',').date.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b03471da-2aaa-4017-a1f8-d870bd6af00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['date','wd','forecast_time', 'forecast', \"forecast_dist\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44978992-7c60-4d80-9f6e-21daa27a8645",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27ca6bea-9980-422f-b77d-40e76b090317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacking_scaled_cross_validation(X, y, model):\n",
    "    if model == None:\n",
    "        return None\n",
    "\n",
    "    print('-----------STACKING CROSS VALIDATION BEGINNING-----------')\n",
    "    split = 10\n",
    "    kf = KFold(n_splits=split, shuffle=True)       \n",
    "    stack_rmse_scores = []\n",
    "    stack_mae_scores = []\n",
    "    i = 1\n",
    "    for (train_index, test_index) in kf.split(pd.DataFrame(X), pd.DataFrame(y)):\n",
    "        X_train, X_test = pd.DataFrame(X).iloc[train_index], pd.DataFrame(X).iloc[test_index]\n",
    "        Y_train, Y_test = pd.DataFrame(y).iloc[train_index],pd.DataFrame(y).iloc[test_index]\n",
    "\n",
    "        model.fit(X_train, Y_train)\n",
    "\n",
    "        prediction = model.predict(X_test)\n",
    "        stack_rmse_scores.append(mean_squared_error(Y_test, prediction,squared=False))\n",
    "        stack_mae_scores.append(mean_absolute_error(Y_test, prediction))\n",
    "        \n",
    "        print(show_evaluation(prediction, Y_test))\n",
    "        print(f'-------------------FOLD {i}-----------------')\n",
    "        i+=1\n",
    "\n",
    "    print('---------------CROSS VALIDATION COMPLETE-------------')\n",
    "    print('--------------------------RMSE-----------------------')\n",
    "    display_scores(stack_rmse_scores)\n",
    "    print('--------------------------MAE------------------------')\n",
    "    display_scores(stack_mae_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee85933e-0529-44a3-b246-f6e9e2f0084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blending ensemble \n",
    "def stacking_model(xgb_params_1, xgb_params_2, lgbm_params_1, lgbm_params_2):\n",
    "    estimators = [\n",
    "#         ('lr', RidgeCV()),\n",
    "#         ('svr', LinearSVR(random_state=42)),\n",
    "#         ('lgbm-1', Pipeline([('scaler', MaxAbsScaler()),('lgbm', LGBMRegressor(**lgbm_params_1))])),\n",
    "#         ('lgbm-2', Pipeline([('scaler', MaxAbsScaler()),('lgbm', LGBMRegressor(**lgbm_params_2))])),        \n",
    "#         ('xgb-1', Pipeline([('scaler', MaxAbsScaler()),('xgb', XGBRegressor(**xgb_params_1))])),\n",
    "#         ('xgb-2', Pipeline([('scaler', MaxAbsScaler()),('xgb', XGBRegressor(**xgb_params_2))])),\n",
    "        ('gboost', GradientBoostingRegressor(n_estimators=3000, \n",
    "                                             learning_rate=0.05, \n",
    "                                             max_depth=7, max_features='sqrt', \n",
    "                                             min_samples_leaf=15, \n",
    "                                             min_samples_split=10, \n",
    "                                             loss='huber', random_state =5)),\n",
    "        ('xtree', ExtraTreesRegressor(n_estimators=200)),\n",
    "        ('lasso', Pipeline([('scaler', MaxAbsScaler()),('xgb', Lasso(alpha =0.0005, random_state=1))])),\n",
    "        ('KRR', KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)),\n",
    "        ('ENet', Pipeline([('scaler', RobustScaler()), ('Eet', ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))])), \n",
    "        ('ridgecv', Pipeline([('scaler', MaxAbsScaler()),('ridgecv', RidgeCV())])),\n",
    "        ('linearsvr', Pipeline([('scaler', MaxAbsScaler()),('svr', LinearSVR())]))\n",
    "    ]\n",
    "\n",
    "    \n",
    "    \n",
    "    # # xtratree = ExtraTreesRegressor(n_estimators=100)\n",
    "# # ridge = make_pipeline(RobustScaler(), RidgeCV())\n",
    "# # lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n",
    "# # SVR = make_pipeline(RobustScaler(), LinearSVR())\n",
    "# # KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n",
    "# # ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n",
    "    \n",
    "    \n",
    "    reg = StackingRegressor(\n",
    "         estimators=estimators,\n",
    "         final_estimator=LinearSVR(random_state=42),\n",
    "         verbose = 10,\n",
    "#          n_jobs = -1\n",
    "    )\n",
    "    \n",
    "#     reg = StackingRegressor(\n",
    "#          estimators=estimators,\n",
    "#          final_estimator=XGBRegressor(random_state=42),\n",
    "#          n_jobs = -1,\n",
    "#          verbose = 10\n",
    "#     )\n",
    "    \n",
    "#     reg = StackingRegressor(\n",
    "#          estimators=estimators,\n",
    "#          final_estimator=RandomForestRegressor(random_state=42),\n",
    "#          verbose = 10, \n",
    "#          n_jobs = -1,\n",
    "#     )\n",
    "    \n",
    "    return reg "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae2eb33-a6b7-42a5-9d72-c742afbaedb0",
   "metadata": {},
   "source": [
    "# Data preparation and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dc1d32-9202-4d51-86a7-c246bda4d349",
   "metadata": {},
   "source": [
    "## WP1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39473823-b3c0-4823-945f-82252d0836de",
   "metadata": {},
   "outputs": [],
   "source": [
    "wp1_X = train_wp1[[c for c in train_wp1 if c not in [\"wp\"]] + [\"wp\"]].drop(to_drop, axis = 1)\n",
    "X1 = wp1_X.drop('wp', axis=1)\n",
    "y1 = wp1_X['wp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa6cd2e4-16bd-40a1-8f3a-a7a074871c4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params_lgbm_1 =   [{\n",
    "    'reg_alpha': 0.25020407037516895,\n",
    "    'reg_lambda': 7.183180037262842,\n",
    "    'colsample_bytree': 1.0,\n",
    "    'subsample': 1.0,\n",
    "    'learning_rate': 0.11751089382716717,\n",
    "    'max_depth': 84,\n",
    "    'num_leaves': 596,\n",
    "    'min_child_samples': 15,\n",
    "}, {\n",
    "    'reg_alpha': 0.8314449043001416,\n",
    "    'reg_lambda': 9.093012403173608,\n",
    "    'colsample_bytree': 0.9,\n",
    "    'subsample': 0.4,\n",
    "    'learning_rate': 0.2033256175102991,\n",
    "    'max_depth': 55,\n",
    "    'num_leaves': 964,\n",
    "    'min_child_samples': 25,\n",
    "}]\n",
    "\n",
    "params_xgb_1 = [{\n",
    "    'lambda': 0.3643806022565838,\n",
    "    'alpha': 0.003650309466012506,\n",
    "    'colsample_bytree': 0.9640425007241273,\n",
    "    'subsample': 0.8,\n",
    "    'learning_rate': 0.052762727588106954,\n",
    "    'n_estimators': 700,\n",
    "    'max_depth': 54,\n",
    "    'min_child_weight': 96,\n",
    "    'eta': 3.119364108002744e-05,\n",
    "    'gamma': 5.177778739056542e-05,\n",
    "    'grow_policy': 'lossguide',\n",
    "}, {\n",
    "    'lambda': 2.1359622347936646,\n",
    "    'alpha': 0.016202766042783825,\n",
    "    'colsample_bytree': 0.8075360516891219,\n",
    "    'subsample': 0.8,\n",
    "    'learning_rate': 0.06792370224097045,\n",
    "    'n_estimators': 320,\n",
    "    'max_depth': 58,\n",
    "    'min_child_weight': 102,\n",
    "    'eta': 6.934521001624072e-05,\n",
    "    'gamma': 4.369012735807193e-06,\n",
    "    'grow_policy': 'lossguide',\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37d762d3-2ed6-4d2a-b0c7-b8ab3037075a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_1 = stacking_model(params_xgb_1[0], params_xgb_1[1], params_lgbm_1[0], params_lgbm_1[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6022a2f2-47bf-471c-9434-af2b39ea2429",
   "metadata": {},
   "source": [
    "## WP2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f706b351-afe7-4d9e-bbb5-d8e0360ab5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "wp2_X = train_wp2[[c for c in train_wp2 if c not in [\"wp\"]] + [\"wp\"]].drop(to_drop, axis = 1)\n",
    "X2 = wp2_X.drop('wp', axis=1)\n",
    "y2 = wp2_X['wp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "575cf4a3-88ca-45ad-b0e0-387e4f99804d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params_lgbm_2 =   [{\n",
    "    'reg_alpha': 0.18268883436586145,\n",
    "    'reg_lambda': 0.15916821051528962,\n",
    "    'colsample_bytree': 1.0,\n",
    "    'subsample': 0.6,\n",
    "    'learning_rate': 0.18007000714755378,\n",
    "    'max_depth': 77,\n",
    "    'num_leaves': 425,\n",
    "    'min_child_samples': 10,\n",
    "    'min_data_per_groups': 19,\n",
    "}, {\n",
    "    'reg_alpha': 0.34026994469471555,\n",
    "    'reg_lambda': 1.1032197453137866,\n",
    "    'colsample_bytree': 0.9,\n",
    "    'subsample': 0.6,\n",
    "    'learning_rate': 0.13414826176962302,\n",
    "    'max_depth': 81,\n",
    "    'num_leaves': 987,\n",
    "    'min_child_samples': 39,\n",
    "}]\n",
    "\n",
    "params_xgb_2 = [{\n",
    "    'lambda': 0.005195058020286749,\n",
    "    'alpha': 0.15427340616771562,\n",
    "    'colsample_bytree': 0.4794118698886291,\n",
    "    'subsample': 0.7,\n",
    "    'learning_rate': 0.13969003989794868,\n",
    "    'n_estimators': 583,\n",
    "    'max_depth': 20,\n",
    "    'min_child_weight': 81,\n",
    "    'eta': 0.0006994052800675432,\n",
    "    'gamma': 4.0927842177131904e-08,\n",
    "    'grow_policy': 'depthwise',\n",
    "}, {\n",
    "    'lambda': 4.982427302967441,\n",
    "    'alpha': 0.023879453147379343,\n",
    "    'colsample_bytree': 0.29850970311481473,\n",
    "    'subsample': 0.7,\n",
    "    'learning_rate': 0.07986759823219342,\n",
    "    'n_estimators': 634,\n",
    "    'max_depth': 52,\n",
    "    'min_child_weight': 142,\n",
    "    'eta': 0.9698508070965183,\n",
    "    'gamma': 6.168834828494383e-06,\n",
    "    'grow_policy': 'depthwise',\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f68707cc-224a-4f75-b5f5-f054e40a3959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_2 = stacking_model(params_xgb_2[0], params_xgb_2[1], params_lgbm_2[0], params_lgbm_2[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2d4dc5-2f59-4184-83cb-dbb4951975c9",
   "metadata": {},
   "source": [
    "## WP3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5163d5b8-ea9c-4c3a-9014-9b15f541925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wp3_X = train_wp3[[c for c in train_wp3 if c not in [\"wp\"]] + [\"wp\"]].drop(to_drop, axis = 1)\n",
    "X3 = wp3_X.drop('wp', axis = 1)\n",
    "y3 = wp3_X['wp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef277fd5-a26e-4004-afd8-97e6120d034e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params_lgbm_3 = [{\n",
    "    'reg_alpha': 0.2380367567801365,\n",
    "    'reg_lambda': 0.005052844767806766,\n",
    "    'colsample_bytree': 0.9,\n",
    "    'subsample': 0.5,\n",
    "    'learning_rate': 0.11958787026894079,\n",
    "    'max_depth': 41,\n",
    "    'num_leaves': 690,\n",
    "}, {\n",
    "    'reg_alpha': 0.26013926149282945,\n",
    "    'reg_lambda': 0.002325658512162904,\n",
    "    'colsample_bytree': 1.0,\n",
    "    'subsample': 0.7,\n",
    "    'learning_rate': 0.10619054458258967,\n",
    "    'max_depth': 83,\n",
    "    'num_leaves': 647,\n",
    "    'min_child_samples': 3,\n",
    "}]   \n",
    "    \n",
    "params_xgb_3 = [{\n",
    "    'lambda': 0.018191871915246106,\n",
    "    'alpha': 0.2397827070234125,\n",
    "    'colsample_bytree': 0.4710946041352672,\n",
    "    'subsample': 0.8,\n",
    "    'learning_rate': 0.14812785561924302,\n",
    "    'n_estimators': 688,\n",
    "    'max_depth': 32,\n",
    "    'min_child_weight': 218,\n",
    "    'eta': 6.950960910550952e-08,\n",
    "    'gamma': 2.0149702062428016e-07,\n",
    "    'grow_policy': 'lossguide',\n",
    "}, {\n",
    "    'lambda': 0.018191871915246106,\n",
    "    'alpha': 0.2397827070234125,\n",
    "    'colsample_bytree': 0.4710946041352672,\n",
    "    'subsample': 0.9,\n",
    "    'learning_rate': 0.11812785561924302,\n",
    "    'n_estimators': 400,\n",
    "    'max_depth': 28,\n",
    "    'min_child_weight': 220,\n",
    "    'eta': 6.950960910550952e-08,\n",
    "    'gamma': 2.0149702062428016e-07,\n",
    "    'grow_policy': 'lossguide',\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "671ea812-5ac9-42de-a83c-54b3426090c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_3 = stacking_model(params_xgb_3[0], params_xgb_3[1], params_lgbm_3[0], params_lgbm_3[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273f92bf-cd57-4163-90ab-c4e98c88aa0a",
   "metadata": {},
   "source": [
    "## WP4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84673a7f-5192-451e-b1e7-c6f8046deb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "wp4_X = train_wp4[[c for c in train_wp4 if c not in [\"wp\"]] + [\"wp\"]].drop(to_drop, axis = 1)\n",
    "X4 = wp4_X.drop('wp', axis = 1)\n",
    "y4 = wp4_X['wp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56dfeafa-025c-487d-9844-318c8a11cc6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params_lgbm_4 = [{\n",
    "    'reg_alpha': 0.08714703614419553,\n",
    "    'reg_lambda': 9.983645262139024,\n",
    "    'colsample_bytree': 0.9,\n",
    "    'subsample': 0.8,\n",
    "    'learning_rate': 0.13413154768816146,\n",
    "    'max_depth': 41,\n",
    "    'num_leaves': 613,\n",
    "    'min_child_samples': 15,\n",
    "}, {\n",
    "    'reg_alpha': 0.15331128149569725,\n",
    "    'reg_lambda': 0.28560184971009756,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'subsample': 0.5,\n",
    "    'learning_rate': 0.11430869527789024,\n",
    "    'max_depth': 24,\n",
    "    'num_leaves': 856,\n",
    "    'min_child_samples': 14,\n",
    "}]\n",
    "\n",
    "params_xgb_4 = [{\n",
    "    'lambda': 0.13763482520556616,\n",
    "    'alpha': 0.0010077676339636944,\n",
    "    'colsample_bytree': 0.954734556572597,\n",
    "    'subsample': 0.8,\n",
    "    'learning_rate': 0.05499114408834853,\n",
    "    'n_estimators': 546,\n",
    "    'max_depth': 43,\n",
    "    'min_child_weight': 94,\n",
    "    'eta': 1.2784286267654713e-06,\n",
    "    'gamma': 1.6935174502873177e-05,\n",
    "    'grow_policy': 'depthwise',\n",
    "}, {\n",
    "    'lambda': 0.001340947773207149,\n",
    "    'alpha': 0.002479638085657274,\n",
    "    'colsample_bytree': 0.3030181981060389,\n",
    "    'subsample': 0.7,\n",
    "    'learning_rate': 0.07696248319007938,\n",
    "    'n_estimators': 367,\n",
    "    'max_depth': 31,\n",
    "    'min_child_weight': 72,\n",
    "    'eta': 3.704957186572025e-08,\n",
    "    'gamma': 8.44315434172209e-05,\n",
    "    'grow_policy': 'depthwise',\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0fc87d25-870c-4f5b-ac4b-6c5b88b89ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_4 = stacking_model(params_xgb_4[0], params_xgb_4[1], params_lgbm_4[0], params_lgbm_4[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb8967b-d516-487d-9a5f-1bdf5d965d41",
   "metadata": {},
   "source": [
    "## WP5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f711b6de-c37a-4af2-86ec-2058d155234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wp5_X = train_wp5[[c for c in train_wp5 if c not in [\"wp\"]] + [\"wp\"]].drop(to_drop, axis = 1)\n",
    "X5 = wp5_X.drop('wp', axis = 1)\n",
    "y5 = wp5_X['wp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f048dba3-0231-4aeb-8aaa-d554594605ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params_lgbm_5 = [{\n",
    "    'reg_alpha': 0.1420112281892889,\n",
    "    'reg_lambda': 0.14745955581286027,\n",
    "    'colsample_bytree': 0.9,\n",
    "    'subsample': 0.7,\n",
    "    'learning_rate': 0.15576554024588912,\n",
    "    'max_depth': 61,\n",
    "    'num_leaves': 483,\n",
    "    'min_child_samples': 10,\n",
    "}, {\n",
    "    'reg_alpha': 0.04781362061382749,\n",
    "    'reg_lambda': 9.716980953182604,\n",
    "    'colsample_bytree': 0.9,\n",
    "    'subsample': 0.7,\n",
    "    'learning_rate': 0.14614317149730652,\n",
    "    'max_depth': 57,\n",
    "    'num_leaves': 532,\n",
    "    'min_child_samples': 7,\n",
    "}]\n",
    "\n",
    "\n",
    "params_xgb_5 = [{\n",
    "    'lambda': 4.7653031074423104,\n",
    "    'alpha': 0.004963619239675007,\n",
    "    'colsample_bytree': 0.8616303151950829,\n",
    "    'subsample': 0.8,\n",
    "    'learning_rate': 0.167247240657064,\n",
    "    'n_estimators': 509,\n",
    "    'max_depth': 31,\n",
    "    'min_child_weight': 73,\n",
    "    'eta': 0.1392993925005545,\n",
    "    'gamma': 1.4909263616645174e-07,\n",
    "    'grow_policy': 'depthwise',\n",
    "}, {\n",
    "    'lambda': 4.537995153532639,\n",
    "    'alpha': 0.15887083612902936,\n",
    "    'colsample_bytree': 0.35129085402309673,\n",
    "    'subsample': 0.8,\n",
    "    'learning_rate': 0.20146110291550628,\n",
    "    'n_estimators': 354,\n",
    "    'max_depth': 27,\n",
    "    'min_child_weight': 91,\n",
    "    'eta': 0.1963402390178624,\n",
    "    'gamma': 4.730295821405375e-07,\n",
    "    'grow_policy': 'lossguide',\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21b613da-05d5-4c00-a4c4-fcc0336fc586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_5 = stacking_model(params_xgb_5[0], params_xgb_5[1], params_lgbm_5[0], params_lgbm_5[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d5b1f0-9cbc-4b4d-80bb-2fcbb5a2a138",
   "metadata": {},
   "source": [
    "## WP6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "038868ba-c901-4e9a-b4d1-cd59bbb32a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wp6_X = train_wp6[[c for c in train_wp6 if c not in [\"wp\"]] + [\"wp\"]].drop(to_drop, axis = 1)\n",
    "X6 = wp6_X.drop('wp', axis = 1)\n",
    "y6 = wp6_X['wp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06f05bae-cf5d-4f74-89ab-28d9aaafee64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params_lgbm_6 = [{\n",
    "    'reg_alpha': 0.19099691249064502,\n",
    "    'reg_lambda': 0.3893771552082417,\n",
    "    'colsample_bytree': 0.6,\n",
    "    'subsample': 0.7,\n",
    "    'learning_rate': 0.10214699989265669,\n",
    "    'max_depth': 70,\n",
    "    'num_leaves': 903,\n",
    "    'min_child_samples': 1,\n",
    "}, {\n",
    "    'reg_alpha': 0.23451110075396234,\n",
    "    'reg_lambda': 0.796705483623135,\n",
    "    'colsample_bytree': 0.9,\n",
    "    'subsample': 0.4,\n",
    "    'learning_rate': 0.1561492653707781,\n",
    "    'max_depth': 67,\n",
    "    'num_leaves': 998,\n",
    "    'min_child_samples': 45,\n",
    "}]\n",
    "\n",
    "params_xgb_6 = [{\n",
    "    'lambda': 6.198890709955999,\n",
    "    'alpha': 0.009212761583335095,\n",
    "    'colsample_bytree': 0.9364947872025757,\n",
    "    'subsample': 0.6,\n",
    "    'learning_rate': 0.0377294321765545,\n",
    "    'n_estimators': 458,\n",
    "    'max_depth': 50,\n",
    "    'min_child_weight': 28,\n",
    "    'eta': 1.0671149195024988e-08,\n",
    "    'gamma': 1.4697758952551594e-05,\n",
    "    'grow_policy': 'depthwise',\n",
    "}, {\n",
    "    'lambda': 0.5705269295320163,\n",
    "    'alpha': 0.06713843687958011,\n",
    "    'colsample_bytree': 0.8718486759988152,\n",
    "    'subsample': 0.8,\n",
    "    'learning_rate': 0.07668854905667996,\n",
    "    'n_estimators': 582,\n",
    "    'max_depth': 49,\n",
    "    'min_child_weight': 143,\n",
    "    'eta': 9.055710235537663e-07,\n",
    "    'gamma': 1.111486195598291e-06,\n",
    "    'grow_policy': 'depthwise',\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "430eab5b-b681-4093-805d-441e9814cfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_6 = stacking_model(params_xgb_6[0], params_xgb_6[1], params_lgbm_6[0], params_lgbm_6[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f798f81-9f98-4889-806d-c3fd68503df0",
   "metadata": {},
   "source": [
    "# Super learner ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec83c430-c3eb-45c7-9259-5d33ba69ece1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Stacking of multiple models\n",
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=6):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            print(f\"-----Model {i}----\")\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) \n",
    "            for model in base_models]).mean(axis=1) \n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dea8bca6-c778-434d-a223-8ca986547e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Stacking of one model\n",
    "class StackingSL_1Model(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_model, meta_model, n_folds=5, verbose=True):\n",
    "        self.base_model = base_model\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "        self.verbose = verbose\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = []\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X_test.shape[0], self.n_folds))\n",
    "        i = 0\n",
    "        for train_index, holdout_index in kfold.split(X_train, y_train):\n",
    "            if self.verbose:\n",
    "                print(f\"--------------Model {i}--------------\")\n",
    "            instance = clone(self.base_model)\n",
    "            self.base_models_.append(instance)\n",
    "            instance.fit(X_train[train_index], y_train[train_index])\n",
    "\n",
    "            prediction = instance.predict(X_test)\n",
    "            print('RMSE: ', mean_squared_error(y_test, prediction,squared=False))\n",
    "            \n",
    "            y_pred = instance.predict(X_test)\n",
    "            out_of_fold_predictions[:,i] = y_pred\n",
    "            i+=1\n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y_test)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([base_model.predict(X) for base_model in self.base_models_ ])\n",
    "        ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfc0c35-727f-4a86-9249-ab6831764939",
   "metadata": {},
   "source": [
    "## Used model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2ad6ad-b133-420f-8ae7-ed24aba4ac4e",
   "metadata": {},
   "source": [
    "|  Farm Nb  | Model | Mean  | Sum up |\n",
    "| --- | --- | --- | --- |\n",
    "|  1   | Full LGBM with first parameters + RidgeCV | 0.0763953044063326 |  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca05de9e-06b1-452f-b54d-6629ee94af33",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # xtratree = ExtraTreesRegressor(n_estimators=100)\n",
    "# # ridge = make_pipeline(RobustScaler(), RidgeCV())\n",
    "# # lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n",
    "# # SVR = make_pipeline(RobustScaler(), LinearSVR())\n",
    "# # KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n",
    "# # ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n",
    "# # GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "# #                                    max_depth=4, max_features='sqrt',\n",
    "# #                                    min_samples_leaf=15, min_samples_split=10, \n",
    "# #                                    loss='huber', random_state =5)\n",
    "\n",
    "# xtratrees = ExtraTreesRegressor(n_estimators=100) \n",
    "# ridgecv = Pipeline([('scaler', MaxAbsScaler()),('ridgecv', RidgeCV())])\n",
    "# linearsvr = Pipeline([('scaler', MaxAbsScaler()),('svr', LinearSVR())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "023ec36a-bd70-4b90-944f-4a55e478e18a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lgbm_a_1 = Pipeline([('scaler', MaxAbsScaler()),('lgbm', LGBMRegressor(**params_lgbm_1[0]))])\n",
    "# lgbm_b_1 = Pipeline([('scaler', MaxAbsScaler()),('lgbm', LGBMRegressor(**params_lgbm_1_bis))])\n",
    "# xgb_a_1 = Pipeline([('scaler', MaxAbsScaler()),('xgb', XGBRegressor(**params_xgb_1))])\n",
    "xgb_b_1 = Pipeline([('scaler', MaxAbsScaler()),('xgb', XGBRegressor(**params_xgb_1[0]))])\n",
    "\n",
    "lgbm_a_2 = Pipeline([('scaler', MaxAbsScaler()),('lgbm', LGBMRegressor(**params_lgbm_2[0]))])\n",
    "# lgbm_b_2 = Pipeline([('scaler', MaxAbsScaler()),('lgbm', LGBMRegressor(**params_lgbm_2_bis))])\n",
    "# xgb_a_2 = Pipeline([('scaler', MaxAbsScaler()),('xgb', XGBRegressor(**params_xgb_2))])\n",
    "xgb_b_2 =Pipeline([('scaler', MaxAbsScaler()),('xgb', XGBRegressor(**params_xgb_2[0]))])\n",
    "\n",
    "lgbm_a_3 = Pipeline([('scaler', MaxAbsScaler()),('lgbm', LGBMRegressor(**params_lgbm_3[0]))])\n",
    "# lgbm_b_3 = Pipeline([('scaler', MaxAbsScaler()),('lgbm', LGBMRegressor(**params_lgbm_3_bis))])\n",
    "# xgb_a_3 = Pipeline([('scaler', MaxAbsScaler()),('xgb', XGBRegressor(**params_xgb_3))])\n",
    "xgb_b_3 =Pipeline([('scaler', MaxAbsScaler()),('xgb', XGBRegressor(**params_xgb_3[0]))])\n",
    "\n",
    "lgbm_a_4 = Pipeline([('scaler', MaxAbsScaler()),('lgbm', LGBMRegressor(**params_lgbm_4[0]))])\n",
    "# lgbm_b_4 = Pipeline([('scaler', MaxAbsScaler()),('lgbm', LGBMRegressor(**params_lgbm_4_bis))])\n",
    "# xgb_a_4 = Pipeline([('scaler', MaxAbsScaler()),('xgb', XGBRegressor(**params_xgb_4))])\n",
    "xgb_b_4 =Pipeline([('scaler', MaxAbsScaler()),('xgb', XGBRegressor(**params_xgb_4[0]))])\n",
    "\n",
    "lgbm_a_5 = Pipeline([('scaler', MaxAbsScaler()),('lgbm', LGBMRegressor(**params_lgbm_5[0]))])\n",
    "# lgbm_b_5 = Pipeline([('scaler', MaxAbsScaler()),('lgbm', LGBMRegressor(**params_lgbm_5_bis))])\n",
    "# xgb_a_5 = Pipeline([('scaler', MaxAbsScaler()),('xgb', XGBRegressor(**params_xgb_5))])\n",
    "xgb_b_5 =Pipeline([('scaler', MaxAbsScaler()),('xgb', XGBRegressor(**params_xgb_5[0]))])\n",
    "\n",
    "lgbm_a_6 = Pipeline([('scaler', MaxAbsScaler()),('lgbm', LGBMRegressor(**params_lgbm_6[0]))])\n",
    "# lgbm_b_6 = Pipeline([('scaler', MaxAbsScaler()),('lgbm', LGBMRegressor(**params_lgbm_6_bis))])\n",
    "# xgb_a_6 = Pipeline([('scaler', MaxAbsScaler()),('xgb', XGBRegressor(**params_xgb_6))])\n",
    "xgb_b_6 =Pipeline([('scaler', MaxAbsScaler()),('xgb', XGBRegressor(**params_xgb_6[0]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fa000723-8204-490d-beed-fc96133ab0fd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_1 = StackingAveragedModels(base_models = (lgbm_a_1, lgbm_a_1, lgbm_a_1, lgbm_a_1, lgbm_a_1), meta_model = RidgeCV(), n_folds=10)\n",
    "# model_2 = StackingAveragedModels(base_models = (lgbm_a_2, lgbm_b_2, xgb_a_2, xgb_b_2, xtratrees, ridgecv, linearsvr), meta_model = RidgeCV(), n_folds=5)\n",
    "# model_3 = StackingAveragedModels(base_models = (lgbm_a_3, lgbm_b_3, xgb_a_3, xgb_b_3, xtratrees, ridgecv, linearsvr), meta_model = RidgeCV(), n_folds=5)\n",
    "# model_4 = StackingAveragedModels(base_models = (lgbm_a_4, lgbm_b_4, xgb_a_4, xgb_b_4, xtratrees, ridgecv, linearsvr), meta_model = RidgeCV(), n_folds=5)\n",
    "# model_5 = StackingAveragedModels(base_models = (lgbm_a_5, lgbm_b_5, xgb_a_5, xgb_b_5, xtratrees, ridgecv, linearsvr), meta_model = RidgeCV(), n_folds=5)\n",
    "# model_6 = StackingAveragedModels(base_models = (lgbm_a_6, lgbm_b_6, xgb_a_6, xgb_b_6, xtratrees, ridgecv, linearsvr), meta_model = RidgeCV(), n_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7ce24f9-abc5-4d23-b024-31ec2bcdb4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = StackingSL_1Model(base_model = lgbm_a_1, meta_model = RidgeCV(), n_folds = 10)\n",
    "model_2 = StackingSL_1Model(base_model = lgbm_a_2, meta_model = RidgeCV(), n_folds = 10)\n",
    "model_3 = StackingSL_1Model(base_model = lgbm_a_3, meta_model = RidgeCV(), n_folds = 10)\n",
    "model_4 = StackingSL_1Model(base_model = lgbm_a_4, meta_model = RidgeCV(), n_folds = 10)\n",
    "model_5 = StackingSL_1Model(base_model = lgbm_a_5, meta_model = RidgeCV(), n_folds = 10)\n",
    "model_6 = StackingSL_1Model(base_model = lgbm_a_6, meta_model = RidgeCV(), n_folds = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a164e61b-064e-4992-9645-8a915f49a455",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = StackingSL_1Model(base_model = xgb_b_1, meta_model = RidgeCV(), n_folds = 10)\n",
    "model_2 = StackingSL_1Model(base_model = xgb_b_2, meta_model = RidgeCV(), n_folds = 10)\n",
    "model_3 = StackingSL_1Model(base_model = xgb_b_3, meta_model = RidgeCV(), n_folds = 10)\n",
    "model_4 = StackingSL_1Model(base_model = xgb_b_4, meta_model = RidgeCV(), n_folds = 10)\n",
    "model_5 = StackingSL_1Model(base_model = xgb_b_5, meta_model = RidgeCV(), n_folds = 10)\n",
    "model_6 = StackingSL_1Model(base_model = xgb_b_6, meta_model = RidgeCV(), n_folds = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fad8637c-ce55-4ce9-ab0c-dbeaed40f9b8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "# model_1 = StackingSL_1Model(base_model = lgbm_a_1, meta_model = RidgeCV(), n_folds = 10, verbose=False)\n",
    "# scores = cross_val_score(model_1, X1.to_numpy(), y1.to_numpy(), scoring='neg_root_mean_squared_error', cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "80788fad-e527-4c61-8ab4-9f3b68c2ccdc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  0.08537310442195084\n",
      "RMSE:  0.0841575428320808\n",
      "RMSE:  0.08464809735234954\n",
      "RMSE:  0.0846063748835966\n",
      "RMSE:  0.08492722751613123\n",
      "RMSE:  0.08462868462638211\n",
      "RMSE:  0.08370718174016292\n",
      "RMSE:  0.08456998921985572\n",
      "RMSE:  0.08435955007073052\n",
      "RMSE:  0.08456615916566892\n",
      "RMSE:  0.08847283132093417\n",
      "RMSE:  0.08835913997172301\n",
      "RMSE:  0.08694363634080843\n",
      "RMSE:  0.0880413180420157\n",
      "RMSE:  0.08739236142779319\n",
      "RMSE:  0.08770476340493649\n",
      "RMSE:  0.08912092198036287\n",
      "RMSE:  0.08728922013864507\n",
      "RMSE:  0.08790317028856709\n",
      "RMSE:  0.08867306935956021\n",
      "RMSE:  0.08661677220783207\n",
      "RMSE:  0.08654310246015315\n",
      "RMSE:  0.08778921415154003\n",
      "RMSE:  0.08796499855926843\n",
      "RMSE:  0.08652472415538871\n",
      "RMSE:  0.0872122596807754\n",
      "RMSE:  0.08801190457245589\n",
      "RMSE:  0.08681677375800191\n",
      "RMSE:  0.08783178809809822\n",
      "RMSE:  0.08733411114278648\n",
      "RMSE:  0.0869424576273622\n",
      "RMSE:  0.08795220955141435\n",
      "RMSE:  0.08605105023823288\n",
      "RMSE:  0.08779348078196264\n",
      "RMSE:  0.08733039112503152\n",
      "RMSE:  0.08781702081926057\n",
      "RMSE:  0.08670183916475853\n",
      "RMSE:  0.08683467624539085\n",
      "RMSE:  0.08806093516012008\n",
      "RMSE:  0.08741863515294937\n",
      "RMSE:  0.08418885861515522\n",
      "RMSE:  0.08500461776253562\n",
      "RMSE:  0.0843293304539113\n",
      "RMSE:  0.08335221795101673\n",
      "RMSE:  0.08563868562090707\n",
      "RMSE:  0.08509040921534684\n",
      "RMSE:  0.08576693582526149\n",
      "RMSE:  0.08617305869536082\n",
      "RMSE:  0.08540926313255914\n",
      "RMSE:  0.08542264967299092\n",
      "RMSE:  0.08368238665319797\n",
      "RMSE:  0.08395239363120362\n",
      "RMSE:  0.0839906900390818\n",
      "RMSE:  0.08513932387141572\n",
      "RMSE:  0.0853634602843064\n",
      "RMSE:  0.08447046729923915\n",
      "RMSE:  0.08438248997560863\n",
      "RMSE:  0.08458004974200437\n",
      "RMSE:  0.08705703625906942\n",
      "RMSE:  0.08413797406845037\n",
      "RMSE:  0.08558093155771197\n",
      "RMSE:  0.08751123116615031\n",
      "RMSE:  0.08681018740516065\n",
      "RMSE:  0.08719964369316918\n",
      "RMSE:  0.08623191031007453\n",
      "RMSE:  0.08742318198270511\n",
      "RMSE:  0.08622058415920902\n",
      "RMSE:  0.08650324749564675\n",
      "RMSE:  0.08709378386768107\n",
      "RMSE:  0.08571863174210914\n",
      "RMSE:  0.08477652802887037\n",
      "RMSE:  0.08710328373821587\n",
      "RMSE:  0.08606638882011333\n",
      "RMSE:  0.08705607339454292\n",
      "RMSE:  0.08643137597114443\n",
      "RMSE:  0.08556813523016968\n",
      "RMSE:  0.08688289815303339\n",
      "RMSE:  0.08613336930640338\n",
      "RMSE:  0.08672154447306565\n",
      "RMSE:  0.08692175188513586\n",
      "RMSE:  0.0867918090082035\n",
      "RMSE:  0.08780715760491344\n",
      "RMSE:  0.08848021608240811\n",
      "RMSE:  0.08673450783531854\n",
      "RMSE:  0.08687931816367996\n",
      "RMSE:  0.08704199670720966\n",
      "RMSE:  0.08801299126991059\n",
      "RMSE:  0.08718406199745254\n",
      "RMSE:  0.08761839190536581\n",
      "RMSE:  0.0885673567826797\n",
      "RMSE:  0.08602689251122139\n",
      "RMSE:  0.08489462575980615\n",
      "RMSE:  0.0864527107672622\n",
      "RMSE:  0.08677865049957624\n",
      "RMSE:  0.08524590409964336\n",
      "RMSE:  0.08746235211790278\n",
      "RMSE:  0.08671234457124173\n",
      "RMSE:  0.08650674288346147\n",
      "RMSE:  0.08583987283316555\n",
      "RMSE:  0.08622176536595859\n",
      "[-0.07849338 -0.08177795 -0.07590999 -0.0783886  -0.07717002 -0.07595102\n",
      " -0.08212167 -0.07828013 -0.08006989 -0.07876605]\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "model_2 = StackingSL_1Model(base_model = lgbm_a_2, meta_model = RidgeCV(), n_folds = 10, verbose=False)\n",
    "scores = cross_val_score(model_2, X2.to_numpy(), y2.to_numpy(), scoring='neg_root_mean_squared_error', cv=cv)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "605bf1f5-0b0f-440c-8d07-174d3aa2a2b1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  0.0721209029346144\n",
      "RMSE:  0.07162806960832122\n",
      "RMSE:  0.07172937392857497\n",
      "RMSE:  0.07193464534183845\n",
      "RMSE:  0.0715189644107414\n",
      "RMSE:  0.07233035930721278\n",
      "RMSE:  0.07214997139505835\n",
      "RMSE:  0.071627655778108\n",
      "RMSE:  0.07188296749169351\n",
      "RMSE:  0.07186835812833606\n",
      "RMSE:  0.0728728314221141\n",
      "RMSE:  0.07294704857734184\n",
      "RMSE:  0.07292028124311156\n",
      "RMSE:  0.07345218052165878\n",
      "RMSE:  0.0726722204037685\n",
      "RMSE:  0.07293379933042\n",
      "RMSE:  0.07457240238323973\n",
      "RMSE:  0.07326316093464307\n",
      "RMSE:  0.07307228078514244\n",
      "RMSE:  0.07351305804205908\n",
      "RMSE:  0.07366698397969929\n",
      "RMSE:  0.07408439567223117\n",
      "RMSE:  0.0738321424640862\n",
      "RMSE:  0.07324207381559958\n",
      "RMSE:  0.07358786506500882\n",
      "RMSE:  0.07381829039644656\n",
      "RMSE:  0.07391444086629487\n",
      "RMSE:  0.07399709772069978\n",
      "RMSE:  0.07293787522952667\n",
      "RMSE:  0.07402623716954927\n",
      "RMSE:  0.07220405740357433\n",
      "RMSE:  0.07263201385023711\n",
      "RMSE:  0.0727336140127155\n",
      "RMSE:  0.07287311476641332\n",
      "RMSE:  0.07182865234531287\n",
      "RMSE:  0.07170299863192454\n",
      "RMSE:  0.07343650010830462\n",
      "RMSE:  0.07204038636234386\n",
      "RMSE:  0.07261798829442682\n",
      "RMSE:  0.07210887481839272\n",
      "RMSE:  0.07415729101642686\n",
      "RMSE:  0.07467718588485488\n",
      "RMSE:  0.07460716410378543\n",
      "RMSE:  0.07412651682763265\n",
      "RMSE:  0.07496083272169042\n",
      "RMSE:  0.07439387637028136\n",
      "RMSE:  0.07473142764327012\n",
      "RMSE:  0.07421983439429487\n",
      "RMSE:  0.07467610973631156\n",
      "RMSE:  0.0757215024092239\n",
      "RMSE:  0.07344951525847757\n",
      "RMSE:  0.07322899742223504\n",
      "RMSE:  0.072823823474742\n",
      "RMSE:  0.07425049654424774\n",
      "RMSE:  0.07392053340040315\n",
      "RMSE:  0.0726866110177357\n",
      "RMSE:  0.07364914183748698\n",
      "RMSE:  0.07527289203516181\n",
      "RMSE:  0.07361506759802919\n",
      "RMSE:  0.07347638423784629\n",
      "RMSE:  0.0736033647417682\n",
      "RMSE:  0.07339962613853941\n",
      "RMSE:  0.07338695034157981\n",
      "RMSE:  0.07267479836052874\n",
      "RMSE:  0.07262657363761682\n",
      "RMSE:  0.07386366502137165\n",
      "RMSE:  0.07310713183560634\n",
      "RMSE:  0.0729281661191042\n",
      "RMSE:  0.07245982692511861\n",
      "RMSE:  0.07264551779735466\n",
      "RMSE:  0.07270520923405607\n",
      "RMSE:  0.0727800255278097\n",
      "RMSE:  0.07270823107710477\n",
      "RMSE:  0.0730185254775273\n",
      "RMSE:  0.07216251920279103\n",
      "RMSE:  0.07236677743902943\n",
      "RMSE:  0.0731015163639472\n",
      "RMSE:  0.07278154478097168\n",
      "RMSE:  0.07198010737273786\n",
      "RMSE:  0.07325810924927212\n",
      "RMSE:  0.07396970404776458\n",
      "RMSE:  0.0735643515648075\n",
      "RMSE:  0.07335266308454448\n",
      "RMSE:  0.07404820062002475\n",
      "RMSE:  0.07321571404847857\n",
      "RMSE:  0.07387556944771485\n",
      "RMSE:  0.07375953663188692\n",
      "RMSE:  0.07379700355965992\n",
      "RMSE:  0.0738925205655151\n",
      "RMSE:  0.07457207968348958\n",
      "RMSE:  0.07518397189617833\n",
      "RMSE:  0.07472331094745463\n",
      "RMSE:  0.0748447903750666\n",
      "RMSE:  0.07442941928426453\n",
      "RMSE:  0.07394361346261184\n",
      "RMSE:  0.07412967753367615\n",
      "RMSE:  0.07514522877776532\n",
      "RMSE:  0.07450783560080783\n",
      "RMSE:  0.07477892499729075\n",
      "RMSE:  0.07469631835589323\n",
      "[-0.06926386 -0.06445538 -0.06995804 -0.06659421 -0.06541249 -0.0657619\n",
      " -0.06475108 -0.06749405 -0.06892513 -0.06742125]\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "model_3= StackingSL_1Model(base_model = lgbm_a_3, meta_model = RidgeCV(), n_folds = 10, verbose=False)\n",
    "scores = cross_val_score(model_3, X3.to_numpy(), y3.to_numpy(), scoring='neg_root_mean_squared_error', cv=cv)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e524686-c27a-43e9-bb24-9c42e578beaf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  0.07778548024492629\n",
      "RMSE:  0.0770839760305003\n",
      "RMSE:  0.07760112502777304\n",
      "RMSE:  0.07727742201348231\n",
      "RMSE:  0.07694068378525351\n",
      "RMSE:  0.07750068743125553\n",
      "RMSE:  0.07732104696988301\n",
      "RMSE:  0.07802981826899393\n",
      "RMSE:  0.07717671327917473\n",
      "RMSE:  0.0774499240814517\n",
      "RMSE:  0.07865473994477253\n",
      "RMSE:  0.07744919087684583\n",
      "RMSE:  0.07762392438756072\n",
      "RMSE:  0.07782198177953156\n",
      "RMSE:  0.07705630441380636\n",
      "RMSE:  0.07774026155520872\n",
      "RMSE:  0.0773218722756629\n",
      "RMSE:  0.07805834800682851\n",
      "RMSE:  0.07754307244129034\n",
      "RMSE:  0.0784698952369617\n",
      "RMSE:  0.0762183645326903\n",
      "RMSE:  0.07593468240952146\n",
      "RMSE:  0.07550751635162495\n",
      "RMSE:  0.07571570548099774\n",
      "RMSE:  0.07582587382409514\n",
      "RMSE:  0.07585375680457455\n",
      "RMSE:  0.07608858085208696\n",
      "RMSE:  0.07630643534763737\n",
      "RMSE:  0.07595169419270346\n",
      "RMSE:  0.0752274476094861\n",
      "RMSE:  0.07661241891093946\n",
      "RMSE:  0.07814757937748198\n",
      "RMSE:  0.0782732365474305\n",
      "RMSE:  0.07739661442099705\n",
      "RMSE:  0.0772361222013884\n",
      "RMSE:  0.07801471091593443\n",
      "RMSE:  0.07778284398405473\n",
      "RMSE:  0.07851754989510726\n",
      "RMSE:  0.07701123068776644\n",
      "RMSE:  0.07859941431414932\n",
      "RMSE:  0.07592418543380838\n",
      "RMSE:  0.07661480594684998\n",
      "RMSE:  0.07614633222711649\n",
      "RMSE:  0.07687873257636263\n",
      "RMSE:  0.07675468829734611\n",
      "RMSE:  0.07672511445823033\n",
      "RMSE:  0.07585934908464671\n",
      "RMSE:  0.07637712485039662\n",
      "RMSE:  0.07641131949290075\n",
      "RMSE:  0.0764019585446461\n",
      "RMSE:  0.07673126325042208\n",
      "RMSE:  0.07858130412091213\n",
      "RMSE:  0.07673950385449035\n",
      "RMSE:  0.07806207500888061\n",
      "RMSE:  0.07767979094630433\n",
      "RMSE:  0.07730797282884252\n",
      "RMSE:  0.07768232756418239\n",
      "RMSE:  0.07670892727480783\n",
      "RMSE:  0.07823468058170617\n",
      "RMSE:  0.07758333707771978\n",
      "RMSE:  0.07874767541724334\n",
      "RMSE:  0.07774913469073098\n",
      "RMSE:  0.07846700061979867\n",
      "RMSE:  0.07754175386214297\n",
      "RMSE:  0.07836343584035259\n",
      "RMSE:  0.07778221498503454\n",
      "RMSE:  0.07807573256747122\n",
      "RMSE:  0.07682091713736625\n",
      "RMSE:  0.0772116644337841\n",
      "RMSE:  0.07807682936779811\n",
      "RMSE:  0.07644052434256203\n",
      "RMSE:  0.07778865718813446\n",
      "RMSE:  0.07677440689501908\n",
      "RMSE:  0.07725013068580935\n",
      "RMSE:  0.07593636740630354\n",
      "RMSE:  0.07641252111491267\n",
      "RMSE:  0.07631227487075391\n",
      "RMSE:  0.07662136834011132\n",
      "RMSE:  0.07588763646989886\n",
      "RMSE:  0.07589434159364504\n",
      "RMSE:  0.07912583668563403\n",
      "RMSE:  0.0798034257681569\n",
      "RMSE:  0.07985384866745104\n",
      "RMSE:  0.07968510676050801\n",
      "RMSE:  0.07916948299886196\n",
      "RMSE:  0.07947830274430424\n",
      "RMSE:  0.0796563936033861\n",
      "RMSE:  0.07969760622258557\n",
      "RMSE:  0.07960883847343872\n",
      "RMSE:  0.07940343653434359\n",
      "RMSE:  0.07600919344568666\n",
      "RMSE:  0.0760739304385527\n",
      "RMSE:  0.07585670915503584\n",
      "RMSE:  0.07511126166423217\n",
      "RMSE:  0.07549482248768172\n",
      "RMSE:  0.07534278915367632\n",
      "RMSE:  0.07488475538337863\n",
      "RMSE:  0.0753426436838518\n",
      "RMSE:  0.07628413983709419\n",
      "RMSE:  0.07543223982852161\n",
      "[-0.07299073 -0.07293323 -0.07297597 -0.07212486 -0.07244114 -0.07271821\n",
      " -0.07281601 -0.07235451 -0.07176637 -0.06828419]\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "model_4 = StackingSL_1Model(base_model = lgbm_a_4, meta_model = RidgeCV(), n_folds = 10, verbose=False)\n",
    "scores = cross_val_score(model_4, X4.to_numpy(), y4.to_numpy(), scoring='neg_root_mean_squared_error', cv=cv)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c28aaa13-55e4-4309-a863-6f9484a7a55b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  0.08967881569734475\n",
      "RMSE:  0.08893459352988951\n",
      "RMSE:  0.0893748230782717\n",
      "RMSE:  0.09065736255707073\n",
      "RMSE:  0.08974255432870423\n",
      "RMSE:  0.09046726952967071\n",
      "RMSE:  0.0911590362049504\n",
      "RMSE:  0.09072194745214282\n",
      "RMSE:  0.08935014877122975\n",
      "RMSE:  0.09038985551583932\n",
      "RMSE:  0.09159610061759843\n",
      "RMSE:  0.09060827605248507\n",
      "RMSE:  0.09158143234274128\n",
      "RMSE:  0.09214452160079518\n",
      "RMSE:  0.09196221763573624\n",
      "RMSE:  0.09068939288030407\n",
      "RMSE:  0.09210075895023999\n",
      "RMSE:  0.09120848448840402\n",
      "RMSE:  0.09186622960391808\n",
      "RMSE:  0.09215038451186709\n",
      "RMSE:  0.0908292525438383\n",
      "RMSE:  0.08917485722101225\n",
      "RMSE:  0.08952026005513258\n",
      "RMSE:  0.0893103570470187\n",
      "RMSE:  0.09005485910276914\n",
      "RMSE:  0.08895881159720041\n",
      "RMSE:  0.08983630302527947\n",
      "RMSE:  0.09028957221926706\n",
      "RMSE:  0.08942325770900589\n",
      "RMSE:  0.08912868801900455\n",
      "RMSE:  0.08989853025574172\n",
      "RMSE:  0.09044607806694784\n",
      "RMSE:  0.08947467576175441\n",
      "RMSE:  0.08977280098998097\n",
      "RMSE:  0.09072889469936149\n",
      "RMSE:  0.08909832269784523\n",
      "RMSE:  0.09024687268081913\n",
      "RMSE:  0.0903196975444555\n",
      "RMSE:  0.09096745977107229\n",
      "RMSE:  0.08937891988765291\n",
      "RMSE:  0.08782341440634889\n",
      "RMSE:  0.08858795695710905\n",
      "RMSE:  0.08833230456953313\n",
      "RMSE:  0.0874769700301669\n",
      "RMSE:  0.08792682908145197\n",
      "RMSE:  0.08783723672992752\n",
      "RMSE:  0.0880496886694077\n",
      "RMSE:  0.08767484350656697\n",
      "RMSE:  0.08817328180020949\n",
      "RMSE:  0.08739153902075436\n",
      "RMSE:  0.08936345431903575\n",
      "RMSE:  0.09105435764714198\n",
      "RMSE:  0.08905855524549433\n",
      "RMSE:  0.08895639692490256\n",
      "RMSE:  0.08908045443323681\n",
      "RMSE:  0.08947779075561411\n",
      "RMSE:  0.0898729633967176\n",
      "RMSE:  0.0885053032334704\n",
      "RMSE:  0.08906274676340636\n",
      "RMSE:  0.091179709132363\n",
      "RMSE:  0.08962095741280737\n",
      "RMSE:  0.09074959171846204\n",
      "RMSE:  0.08976674235864786\n",
      "RMSE:  0.08966485963308404\n",
      "RMSE:  0.09016556701077004\n",
      "RMSE:  0.09007972835983255\n",
      "RMSE:  0.08953074185942596\n",
      "RMSE:  0.09062777365456016\n",
      "RMSE:  0.09020195848241623\n",
      "RMSE:  0.0889019145289275\n",
      "RMSE:  0.09120458029264691\n",
      "RMSE:  0.0903317497433013\n",
      "RMSE:  0.09053739761957018\n",
      "RMSE:  0.09085271210541264\n",
      "RMSE:  0.08996661239278628\n",
      "RMSE:  0.09068070780777986\n",
      "RMSE:  0.09075060515081203\n",
      "RMSE:  0.09170997425291585\n",
      "RMSE:  0.09065788152429387\n",
      "RMSE:  0.09261950902013767\n",
      "RMSE:  0.08983538192931678\n",
      "RMSE:  0.08910785508050158\n",
      "RMSE:  0.09001423912572815\n",
      "RMSE:  0.09018049476179885\n",
      "RMSE:  0.08958572436003373\n",
      "RMSE:  0.08843593462987288\n",
      "RMSE:  0.08879139558345632\n",
      "RMSE:  0.08902978644704443\n",
      "RMSE:  0.08963338950186972\n",
      "RMSE:  0.09052288101086327\n",
      "RMSE:  0.08835991859824054\n",
      "RMSE:  0.08846241815274368\n",
      "RMSE:  0.08831889133648577\n",
      "RMSE:  0.08813669887449625\n",
      "RMSE:  0.08885481395949188\n",
      "RMSE:  0.08857646662699187\n",
      "RMSE:  0.08857109239266593\n",
      "RMSE:  0.0880575848613704\n",
      "RMSE:  0.0887474399625401\n",
      "RMSE:  0.08886974872965138\n",
      "[-0.08211472 -0.0831687  -0.0812153  -0.08224764 -0.08601911 -0.08183629\n",
      " -0.08315503 -0.08136837 -0.08104524 -0.08241067]\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "model_5 = StackingSL_1Model(base_model = lgbm_a_5, meta_model = RidgeCV(), n_folds = 10, verbose=False)\n",
    "scores = cross_val_score(model_5, X5.to_numpy(), y5.to_numpy(), scoring='neg_root_mean_squared_error', cv=cv)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4dbdc5ad-9ef0-4566-a428-fcd14af09e0c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  0.06821334738630719\n",
      "RMSE:  0.06738719331850924\n",
      "RMSE:  0.06812490077564919\n",
      "RMSE:  0.0682148663356544\n",
      "RMSE:  0.06797425274897238\n",
      "RMSE:  0.06660812923131768\n",
      "RMSE:  0.06719439397581332\n",
      "RMSE:  0.06893946077801393\n",
      "RMSE:  0.06724577840743415\n",
      "RMSE:  0.06827237090055041\n",
      "RMSE:  0.06887817324753118\n",
      "RMSE:  0.06952382716103626\n",
      "RMSE:  0.06864691507595408\n",
      "RMSE:  0.06947056885237539\n",
      "RMSE:  0.0689713876683276\n",
      "RMSE:  0.06931164918256609\n",
      "RMSE:  0.06914643824516915\n",
      "RMSE:  0.06904309604190137\n",
      "RMSE:  0.06896354458786558\n",
      "RMSE:  0.06932120979345587\n",
      "RMSE:  0.06942232385613219\n",
      "RMSE:  0.06857738328193871\n",
      "RMSE:  0.06812733950836822\n",
      "RMSE:  0.06827649403527267\n",
      "RMSE:  0.06904521589367099\n",
      "RMSE:  0.06840280728082766\n",
      "RMSE:  0.06922462112352971\n",
      "RMSE:  0.06897033095178379\n",
      "RMSE:  0.06872936977186596\n",
      "RMSE:  0.06888333682127411\n",
      "RMSE:  0.06882258617776106\n",
      "RMSE:  0.06855556578391792\n",
      "RMSE:  0.06884907657132236\n",
      "RMSE:  0.06888529166737023\n",
      "RMSE:  0.06899343570667985\n",
      "RMSE:  0.06858233230578084\n",
      "RMSE:  0.06883574919954837\n",
      "RMSE:  0.06902790765007326\n",
      "RMSE:  0.06882715176465977\n",
      "RMSE:  0.06931299223056035\n",
      "RMSE:  0.06688343326263575\n",
      "RMSE:  0.06762700525104745\n",
      "RMSE:  0.0679694076395069\n",
      "RMSE:  0.06760751434622284\n",
      "RMSE:  0.06811883114894467\n",
      "RMSE:  0.06765131502065859\n",
      "RMSE:  0.06801079740725101\n",
      "RMSE:  0.06856744834931978\n",
      "RMSE:  0.06741610977292158\n",
      "RMSE:  0.06779159343217463\n",
      "RMSE:  0.06838169518095112\n",
      "RMSE:  0.0681851099186524\n",
      "RMSE:  0.0685731357775197\n",
      "RMSE:  0.06880703773519238\n",
      "RMSE:  0.068822676887103\n",
      "RMSE:  0.068526305449623\n",
      "RMSE:  0.06886249162228346\n",
      "RMSE:  0.06943953112880938\n",
      "RMSE:  0.06926416514468947\n",
      "RMSE:  0.06914740309186047\n",
      "RMSE:  0.06836817386344189\n",
      "RMSE:  0.06789799650994005\n",
      "RMSE:  0.06715063202836836\n",
      "RMSE:  0.06788055773932336\n",
      "RMSE:  0.06794638758518026\n",
      "RMSE:  0.06714908922854976\n",
      "RMSE:  0.06763265447200743\n",
      "RMSE:  0.06782973852050413\n",
      "RMSE:  0.06794997745823785\n",
      "RMSE:  0.06737580209833169\n",
      "RMSE:  0.06680111353140011\n",
      "RMSE:  0.06668017766227953\n",
      "RMSE:  0.06747572699333335\n",
      "RMSE:  0.06668393203646278\n",
      "RMSE:  0.06662146306051558\n",
      "RMSE:  0.06679390480672404\n",
      "RMSE:  0.06733448806250224\n",
      "RMSE:  0.06705598091590009\n",
      "RMSE:  0.06687211078240307\n",
      "RMSE:  0.0666493701258111\n",
      "RMSE:  0.06881818551582505\n",
      "RMSE:  0.06936743844421955\n",
      "RMSE:  0.06844538712381638\n",
      "RMSE:  0.06914737289221168\n",
      "RMSE:  0.06843021817827172\n",
      "RMSE:  0.06856600162822606\n",
      "RMSE:  0.06910708572588463\n",
      "RMSE:  0.06937391047281947\n",
      "RMSE:  0.06898263635951275\n",
      "RMSE:  0.06818683461093746\n",
      "RMSE:  0.06754272631049524\n",
      "RMSE:  0.06704334436919916\n",
      "RMSE:  0.06735431190814176\n",
      "RMSE:  0.06671405691705992\n",
      "RMSE:  0.06653738637026178\n",
      "RMSE:  0.06594557195291863\n",
      "RMSE:  0.06719372897033456\n",
      "RMSE:  0.06660645005895371\n",
      "RMSE:  0.06737333040302694\n",
      "RMSE:  0.06741576843002264\n",
      "[-0.06406778 -0.06134461 -0.06243713 -0.06305245 -0.0614413  -0.06186434\n",
      " -0.06392709 -0.06295568 -0.06309749 -0.06208673]\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "model_6 = StackingSL_1Model(base_model = lgbm_a_6, meta_model = RidgeCV(), n_folds = 10, verbose=False)\n",
    "scores = cross_val_score(model_6, X6.to_numpy(), y6.to_numpy(), scoring='neg_root_mean_squared_error', cv=cv)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0905a9-40eb-4356-a6d6-f94184795224",
   "metadata": {},
   "source": [
    "# Predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ab4a8367-cf20-4315-afec-7f79878102e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop_test = ['date','wd','forecast_time', 'forecast', \"forecast_dist\", 'wp']\n",
    "def make_prediction_dataset(test, to_drop=to_drop_test):\n",
    "    test_to_predict = test.dropna(subset=['ws','u','v'], how = 'any') # keeps only lines with u,v,ws,wd\n",
    "    test_to_predict = test_to_predict[test_to_predict['wp'].isna()] # keeps only lines with no wp\n",
    "    test_to_predict = test_to_predict.sort_values(by=['date', 'forecast_time'], ascending = [True, False]).drop_duplicates(subset='date')\n",
    "    test_to_predict = test_to_predict.drop(to_drop, axis = 1)\n",
    "    return test_to_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "787439b7-6c92-42ef-b540-cda0dc986fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission_file(lst_X_trains, lst_y_trains, lst_tests, lst_models, dates):\n",
    "    i = 1\n",
    "    lst_prediction = []\n",
    "    lst_models_trained = []\n",
    "    for X, y, test, model in zip(lst_X_trains, lst_y_trains, lst_tests, lst_models):\n",
    "        print(f'--------------Dataset {i}--------------')\n",
    "        X = X.to_numpy()\n",
    "        y = y.to_numpy()\n",
    "        test = test.to_numpy()\n",
    "        model.fit(X, y)\n",
    "        print(f'True:\\n\\tMin:{min(y)}\\n\\tMax:{max(y)}\\n\\tMean:{y.mean()}')\n",
    "        predictions = model.predict(test)\n",
    "        print(f'Prediction:\\n\\tMin:{min(predictions)}\\n\\tMax:{max(predictions)}\\n\\tMean:{np.mean(predictions)}')\n",
    "        predictions = [min(y) if i < 0 else i for i in predictions]\n",
    "        predictions = [max(y) if i > max(y) else i for i in predictions]\n",
    "        print(f'Prediction corrected:\\n\\tMin:{min(predictions)}\\n\\tMax:{max(predictions)}\\n\\tMean:{np.mean(predictions)}')\n",
    "        lst_prediction.append(predictions)\n",
    "        lst_models_trained.append(model)\n",
    "        i+=1\n",
    "    \n",
    "    df_predictions = pd.DataFrame({\n",
    "        'date': test_dates,\n",
    "        'wp1': lst_prediction[0],\n",
    "        'wp2': lst_prediction[1],\n",
    "        'wp3': lst_prediction[2],\n",
    "        'wp4': lst_prediction[3],\n",
    "        'wp5': lst_prediction[4],\n",
    "        'wp6': lst_prediction[5],        \n",
    "    })\n",
    "    return df_predictions, lst_models_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4e500e68-a4c6-493c-87ab-bbab9199f27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_models = [model_1, model_2, model_3, model_4, model_5, model_6]\n",
    "lst_X_trains = [X1, X2, X3, X4, X5, X6]\n",
    "lst_y_trains = [y1, y2, y3, y4, y5, y6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a60d7dcd-85e7-4d07-990b-7b17cd2010e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_tests = []\n",
    "for test in [test_wp1, test_wp2, test_wp3, test_wp4, test_wp5, test_wp6]:\n",
    "    test = make_prediction_dataset(test)\n",
    "    lst_tests.append(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becbb508-0320-4a9c-a7dd-05db21988b62",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "26d8d32a-6e49-4bc8-b7c3-cb0e26082de3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------Dataset 1--------------\n",
      "--------------Model 0--------------\n",
      "RMSE:  0.07529842150612473\n",
      "--------------Model 1--------------\n",
      "RMSE:  0.07535892470867307\n",
      "--------------Model 2--------------\n",
      "RMSE:  0.0749919163366538\n",
      "--------------Model 3--------------\n",
      "RMSE:  0.07544939024175346\n",
      "--------------Model 4--------------\n",
      "RMSE:  0.07513841342978832\n",
      "--------------Model 5--------------\n",
      "RMSE:  0.07554426825843777\n",
      "--------------Model 6--------------\n",
      "RMSE:  0.0750755279433959\n",
      "--------------Model 7--------------\n",
      "RMSE:  0.07471469819200922\n",
      "--------------Model 8--------------\n",
      "RMSE:  0.07566117043910774\n",
      "--------------Model 9--------------\n",
      "RMSE:  0.0751992422379069\n",
      "True:\n",
      "\tMin:0.0\n",
      "\tMax:0.96\n",
      "\tMean:0.2845981952075702\n",
      "Prediction:\n",
      "\tMin:-0.049120048747982925\n",
      "\tMax:0.993353147699862\n",
      "\tMean:0.2980876403053471\n",
      "Prediction corrected:\n",
      "\tMin:0.0\n",
      "\tMax:0.96\n",
      "\tMean:0.29828669811827835\n",
      "--------------Dataset 2--------------\n",
      "--------------Model 0--------------\n",
      "RMSE:  0.08092590369435002\n",
      "--------------Model 1--------------\n",
      "RMSE:  0.08100944792187491\n",
      "--------------Model 2--------------\n",
      "RMSE:  0.08112491760067198\n",
      "--------------Model 3--------------\n",
      "RMSE:  0.08048812189569428\n",
      "--------------Model 4--------------\n",
      "RMSE:  0.08012620470470089\n",
      "--------------Model 5--------------\n",
      "RMSE:  0.08116967850924343\n",
      "--------------Model 6--------------\n",
      "RMSE:  0.08150732587216704\n",
      "--------------Model 7--------------\n",
      "RMSE:  0.08048943122644758\n",
      "--------------Model 8--------------\n",
      "RMSE:  0.08171555177481138\n",
      "--------------Model 9--------------\n",
      "RMSE:  0.08045870788071775\n",
      "True:\n",
      "\tMin:0.0\n",
      "\tMax:0.966\n",
      "\tMean:0.25890153769841273\n",
      "Prediction:\n",
      "\tMin:-0.0364565093328042\n",
      "\tMax:1.0360046450401943\n",
      "\tMean:0.25431637477059205\n",
      "Prediction corrected:\n",
      "\tMin:0.0\n",
      "\tMax:0.966\n",
      "\tMean:0.2543474483022375\n",
      "--------------Dataset 3--------------\n",
      "--------------Model 0--------------\n",
      "RMSE:  0.06899436898550529\n",
      "--------------Model 1--------------\n",
      "RMSE:  0.06763150263436382\n",
      "--------------Model 2--------------\n",
      "RMSE:  0.06839942180748347\n",
      "--------------Model 3--------------\n",
      "RMSE:  0.06806850362919599\n",
      "--------------Model 4--------------\n",
      "RMSE:  0.06846424597238314\n",
      "--------------Model 5--------------\n",
      "RMSE:  0.06852575384323017\n",
      "--------------Model 6--------------\n",
      "RMSE:  0.06816587320558841\n",
      "--------------Model 7--------------\n",
      "RMSE:  0.0685672246254816\n",
      "--------------Model 8--------------\n",
      "RMSE:  0.06908079955409589\n",
      "--------------Model 9--------------\n",
      "RMSE:  0.06885699468423555\n",
      "True:\n",
      "\tMin:0.0\n",
      "\tMax:0.989\n",
      "\tMean:0.2625247252747253\n",
      "Prediction:\n",
      "\tMin:-0.07472701626619696\n",
      "\tMax:1.0286574514285944\n",
      "\tMean:0.29160297770488014\n",
      "Prediction corrected:\n",
      "\tMin:0.0\n",
      "\tMax:0.989\n",
      "\tMean:0.29193778167965656\n",
      "--------------Dataset 4--------------\n",
      "--------------Model 0--------------\n",
      "RMSE:  0.07270669387323185\n",
      "--------------Model 1--------------\n",
      "RMSE:  0.07330422808819184\n",
      "--------------Model 2--------------\n",
      "RMSE:  0.07287512525292486\n",
      "--------------Model 3--------------\n",
      "RMSE:  0.0727782599010622\n",
      "--------------Model 4--------------\n",
      "RMSE:  0.07291766016048115\n",
      "--------------Model 5--------------\n",
      "RMSE:  0.07281119966239988\n",
      "--------------Model 6--------------\n",
      "RMSE:  0.0726618090078232\n",
      "--------------Model 7--------------\n",
      "RMSE:  0.07264533891916125\n",
      "--------------Model 8--------------\n",
      "RMSE:  0.07255203884997988\n",
      "--------------Model 9--------------\n",
      "RMSE:  0.07229680498930705\n",
      "True:\n",
      "\tMin:0.0\n",
      "\tMax:0.992\n",
      "\tMean:0.2763637820512821\n",
      "Prediction:\n",
      "\tMin:-0.030788192051729044\n",
      "\tMax:1.0077703094095771\n",
      "\tMean:0.2840296918437973\n",
      "Prediction corrected:\n",
      "\tMin:0.0\n",
      "\tMax:0.992\n",
      "\tMean:0.2843332490749772\n",
      "--------------Dataset 5--------------\n",
      "--------------Model 0--------------\n",
      "RMSE:  0.08382841133862387\n",
      "--------------Model 1--------------\n",
      "RMSE:  0.08470988422372393\n",
      "--------------Model 2--------------\n",
      "RMSE:  0.08521703063843508\n",
      "--------------Model 3--------------\n",
      "RMSE:  0.08458019531584779\n",
      "--------------Model 4--------------\n",
      "RMSE:  0.08523605638026918\n",
      "--------------Model 5--------------\n",
      "RMSE:  0.0853488720402696\n",
      "--------------Model 6--------------\n",
      "RMSE:  0.08405510454936316\n",
      "--------------Model 7--------------\n",
      "RMSE:  0.0841903859167124\n",
      "--------------Model 8--------------\n",
      "RMSE:  0.08527654361096598\n",
      "--------------Model 9--------------\n",
      "RMSE:  0.08481852130862245\n",
      "True:\n",
      "\tMin:0.0\n",
      "\tMax:0.978\n",
      "\tMean:0.32622119200244204\n",
      "Prediction:\n",
      "\tMin:-0.03557372852811287\n",
      "\tMax:1.0118524743019028\n",
      "\tMean:0.3360179518068565\n",
      "Prediction corrected:\n",
      "\tMin:0.0\n",
      "\tMax:0.978\n",
      "\tMean:0.33602363614441716\n",
      "--------------Dataset 6--------------\n",
      "--------------Model 0--------------\n",
      "RMSE:  0.060042332548380734\n",
      "--------------Model 1--------------\n",
      "RMSE:  0.06026274708484102\n",
      "--------------Model 2--------------\n",
      "RMSE:  0.059910779594744064\n",
      "--------------Model 3--------------\n",
      "RMSE:  0.060395536947970424\n",
      "--------------Model 4--------------\n",
      "RMSE:  0.06010957625904591\n",
      "--------------Model 5--------------\n",
      "RMSE:  0.06055074112048105\n",
      "--------------Model 6--------------\n",
      "RMSE:  0.05990600957235416\n",
      "--------------Model 7--------------\n",
      "RMSE:  0.0602797043171305\n",
      "--------------Model 8--------------\n",
      "RMSE:  0.06103190746625818\n",
      "--------------Model 9--------------\n",
      "RMSE:  0.060269585054439925\n",
      "True:\n",
      "\tMin:0.0\n",
      "\tMax:0.947\n",
      "\tMean:0.2425176472832723\n",
      "Prediction:\n",
      "\tMin:-0.023550039645757553\n",
      "\tMax:0.9187072735086061\n",
      "\tMean:0.23737229282168062\n",
      "Prediction corrected:\n",
      "\tMin:0.0\n",
      "\tMax:0.9187072735086061\n",
      "\tMean:0.23749025709504076\n"
     ]
    }
   ],
   "source": [
    "df_predictions, lst_models_trained = make_submission_file(lst_X_trains, lst_y_trains, lst_tests, lst_models, test_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1bddcaf4-3b78-4794-8260-415f8f37871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_sub = 33\n",
    "model = \"blending_stacking\"\n",
    "lvl0 = \"0-10-XGBOOST\"\n",
    "lvl1 = \"1-RidgeCV\"\n",
    "prepro = 'MaxAbs for all'\n",
    "postpro = \"Prediction limited by X_train min&max\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e4e8d0d3-e657-4682-b2a5-9268f92be5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions.to_csv(f'Predictions/submission_nb_{nb_sub}_{model}_{lvl0}_{lvl1}.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0a0c6290-64a3-4e21-a045-d8b9df7fac7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f = open(f\"Predictions/submission-{nb_sub}_{model}_{lvl0}_{lvl1}.txt\", \"x\")\n",
    "# f.write(f\"params_lgbm_1 = {str(params_lgbm_1)}\\nparams_xgb_1 = {str(params_xgb_1)}\\n\")\n",
    "# f.write(f\"params_lgbm_1_bis = {str(params_lgbm_1_bis)}\\nparams_xgb_1_bis = {str(params_xgb_1_bis)}\\n\\n\")\n",
    "# f.write(f\"params_lgbm_2 = {str(params_lgbm_2)}\\nparams_xgb_2 = {str(params_xgb_2)}\\n\")\n",
    "# f.write(f\"params_lgbm_2_bis = {str(params_lgbm_2_bis)}\\nparams_xgb_2_bis = {str(params_xgb_2_bis)}\\n\\n\")\n",
    "# f.write(f\"params_lgbm_3 = {str(params_lgbm_3)}\\nparams_xgb_3 = {str(params_xgb_3)}\\n\")\n",
    "# f.write(f\"params_lgbm_3_bis = {str(params_lgbm_3_bis)}\\nparams_xgb_3_bis = {str(params_xgb_3_bis)}\\n\\n\")\n",
    "# f.write(f\"params_lgbm_4 = {str(params_lgbm_4)}\\nparams_xgb_4 = {str(params_xgb_4)}\\n\")\n",
    "# f.write(f\"params_lgbm_4_bis = {str(params_lgbm_4_bis)}\\nparams_xgb_4_bis = {str(params_xgb_4_bis)}\\n\\n\")\n",
    "# f.write(f\"params_lgbm_5 = {str(params_lgbm_5)}\\nparams_xgb_5 = {str(params_xgb_5)}\\n\")\n",
    "# f.write(f\"params_lgbm_5_bis = {str(params_lgbm_5_bis)}\\nparams_xgb_5_bis = {str(params_xgb_5_bis)}\\n\\n\")\n",
    "# f.write(f\"params_lgbm_6 = {str(params_lgbm_6)}\\nparams_xgb_6 = {str(params_xgb_6)}\\n\")\n",
    "# f.write(f\"params_lgbm_6_bis = {str(params_lgbm_6_bis)}\\nparams_xgb_6_bis = {str(params_xgb_6_bis)}\\n\\n\")\n",
    "\n",
    "f.write(\"Level 0 estimators:\")\n",
    "f.write(f\"params_xgb_1 = {str(params_xgb_1[0])}\\n\")\n",
    "f.write(f\"params_xgb_2 = {str(params_xgb_2[0])}\\n\")\n",
    "f.write(f\"params_xgb_3 = {str(params_xgb_3[0])}\\n\")\n",
    "f.write(f\"params_xgb_4 = {str(params_xgb_4[0])}\\n\")\n",
    "f.write(f\"params_xgb_5 = {str(params_xgb_5[0])}\\n\")\n",
    "f.write(f\"params_xgb_6 = {str(params_xgb_6[0])}\\n All with MaxAbs scaler\")\n",
    "\n",
    "# f.write(\"('gboost', GradientBoostingRegressor(n_estimators=3000,\\nlearning_rate=0.05,\\nmax_depth=4, max_features='sqrt',\\nmin_samples_leaf=15, \\nmin_samples_split=10, \\nloss='huber', random_state =5)),\\n\\n('xtree', ExtraTreesRegressor(n_estimators=100)),\\n('lasso', Pipeline([('scaler', MaxAbsScaler()),('xgb', Lasso(alpha =0.0005, random_state=1))])),\\n('KRR', KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)),\\n('ENet', Pipeline([('scaler', RobustScaler()), ('Eet', ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))])),\\n('ridgecv', Pipeline([('scaler', MaxAbsScaler()),('ridgecv', RidgeCV())])),\\n('linearsvr', Pipeline([('scaler', MaxAbsScaler()),('svr', LinearSVR())]))\\n\")\n",
    "# f.write(f\"xtratree = ExtraTreesRegressor(n_estimators=100)\\n ridge = make_pipeline(RobustScaler(), RidgeCV())\\n lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\\n SVR = make_pipeline(RobustScaler(), LinearSVR())\\n KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\\n ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\\n GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\\nmax_depth=4, max_features='sqrt',\\nmin_samples_leaf=15, min_samples_split=10, \\nloss='huber', random_state =5)\\n\")\n",
    "# f.write(f\"2 lgbm and 2 xgboost with parameters above and MaxAbsScaler.\\ntratrees = ExtraTreesRegressor(n_estimators=100)\\nridgecv = Pipeline([('scaler', MaxAbsScaler()),('ridgecv', RidgeCV())])\\nlinearsvr = Pipeline([('scaler', MaxAbsScaler()),('svr', LinearSVR())])\")\n",
    "\n",
    "# f.write(f\"Preprocessing: {prepro}\\n\")\n",
    "# f.write(f\"Postprocessing: {postpro}\\n\")\n",
    "\n",
    "f.write(f\"Level1 estimator: {lvl1}\\n\")\n",
    "f.write(f\"Models under the name: {model}_{lvl0}_{lvl1}\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdf7692-020d-43d9-a644-0c28ddf87e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_model = f\"Models/Stacking/model_1-{model}_{lvl0}_{lvl1}.pkl\"\n",
    "with open(pkl_model, 'wb') as file:\n",
    "    pickle.dump(lst_models_trained[0], file)\n",
    "    \n",
    "    \n",
    "pkl_model = f\"Models/Stacking/model_2-{model}_{lvl0}_{lvl1}.pkl\"\n",
    "with open(pkl_model, 'wb') as file:\n",
    "    pickle.dump(lst_models_trained[1], file)\n",
    "    \n",
    "\n",
    "pkl_model = f\"Models/Stacking/model_3-{model}_{lvl0}_{lvl1}.pkl\"\n",
    "with open(pkl_model, 'wb') as file:\n",
    "    pickle.dump(lst_models_trained[2], file)\n",
    "\n",
    "\n",
    "pkl_model = f\"Models/Stacking/model_4-{model}_{lvl0}_{lvl1}.pkl\"\n",
    "with open(pkl_model, 'wb') as file:\n",
    "    pickle.dump(lst_models_trained[3], file)\n",
    "\n",
    "\n",
    "pkl_model = f\"Models/Stacking/model_5-{model}_{lvl0}_{lvl1}.pkl\"\n",
    "with open(pkl_model, 'wb') as file:\n",
    "    pickle.dump(lst_models_trained[4], file)\n",
    "\n",
    "\n",
    "pkl_model = f\"Models/Stacking/model_6-{model}_{lvl0}_{lvl1}.pkl\"\n",
    "with open(pkl_model, 'wb') as file:\n",
    "    pickle.dump(lst_models_trained[5], file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
