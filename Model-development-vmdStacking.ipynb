{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87f2b96a-5b8f-49c2-bb10-d56eea7c9473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import openpyxl\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18142a1a-449c-4056-ad68-3704c86e321a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbdb953f-9b6c-402f-97a7-694ea991772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor, RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC, RidgeCV, Ridge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.svm import LinearSVR\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from vmdpy import VMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfbdb5cf-fddb-4c1d-8d99-5712adf34c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Functions.helper_functions import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b402172-9749-43c5-a553-c94813496dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0038d4f6-5114-412b-b438-324e4d0ccbf3",
   "metadata": {},
   "source": [
    "# Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb7ce6b3-5881-4db0-87ca-244b7161cd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wp1 = pd.read_csv('Data/Preprocessing/WP1_train_preprocessed.csv', sep=',')\n",
    "train_wp2 = pd.read_csv('Data/Preprocessing/WP2_train_preprocessed.csv', sep=',')\n",
    "train_wp3 = pd.read_csv('Data/Preprocessing/WP3_train_preprocessed.csv', sep=',')\n",
    "train_wp4 = pd.read_csv('Data/Preprocessing/WP4_train_preprocessed.csv', sep=',')\n",
    "train_wp5 = pd.read_csv('Data/Preprocessing/WP5_train_preprocessed.csv', sep=',')\n",
    "train_wp6 = pd.read_csv('Data/Preprocessing/WP6_train_preprocessed.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88839967-5d4a-4ed6-b3ad-2ed819309b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_wp1 = pd.read_csv('Data/Preprocessing/WP1_test_preprocessed.csv', sep=',')\n",
    "test_wp2 = pd.read_csv('Data/Preprocessing/WP2_test_preprocessed.csv', sep=',')\n",
    "test_wp3 = pd.read_csv('Data/Preprocessing/WP3_test_preprocessed.csv', sep=',')\n",
    "test_wp4 = pd.read_csv('Data/Preprocessing/WP4_test_preprocessed.csv', sep=',')\n",
    "test_wp5 = pd.read_csv('Data/Preprocessing/WP5_test_preprocessed.csv', sep=',')\n",
    "test_wp6 = pd.read_csv('Data/Preprocessing/WP6_test_preprocessed.csv', sep=',')\n",
    "test_dates = pd.read_csv('Data/Initial/test.csv', sep=',').date.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b03471da-2aaa-4017-a1f8-d870bd6af00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['date','wd','forecast_time', 'forecast', \"forecast_dist\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44978992-7c60-4d80-9f6e-21daa27a8645",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27ca6bea-9980-422f-b77d-40e76b090317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacking_scaled_cross_validation(X, y, model):\n",
    "    if model == None:\n",
    "        return None\n",
    "\n",
    "    print('-----------STACKING CROSS VALIDATION BEGINNING-----------')\n",
    "    split = 10\n",
    "    kf = KFold(n_splits=split, shuffle=True)       \n",
    "    stack_rmse_scores = []\n",
    "    stack_mae_scores = []\n",
    "    i = 1\n",
    "    for (train_index, test_index) in kf.split(pd.DataFrame(X), pd.DataFrame(y)):\n",
    "        X_train, X_test = pd.DataFrame(X).iloc[train_index], pd.DataFrame(X).iloc[test_index]\n",
    "        Y_train, Y_test = pd.DataFrame(y).iloc[train_index],pd.DataFrame(y).iloc[test_index]\n",
    "\n",
    "        model.fit(X_train, Y_train)\n",
    "\n",
    "        prediction = model.predict(X_test)\n",
    "        stack_rmse_scores.append(mean_squared_error(Y_test, prediction,squared=False))\n",
    "        stack_mae_scores.append(mean_absolute_error(Y_test, prediction))\n",
    "        \n",
    "        print(show_evaluation(prediction, Y_test))\n",
    "        print(f'-------------------FOLD {i}-----------------')\n",
    "        i+=1\n",
    "\n",
    "    print('---------------CROSS VALIDATION COMPLETE-------------')\n",
    "    print('--------------------------RMSE-----------------------')\n",
    "    display_scores(stack_rmse_scores)\n",
    "    print('--------------------------MAE------------------------')\n",
    "    display_scores(stack_mae_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee85933e-0529-44a3-b246-f6e9e2f0084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blending ensemble \n",
    "def stacking_model(xgb_params_1, xgb_params_2, lgbm_params_1, lgbm_params_2):\n",
    "    estimators = [\n",
    "#         ('lr', RidgeCV()),\n",
    "#         ('svr', LinearSVR(random_state=42)),\n",
    "#         ('lgbm-1', Pipeline([('scaler', MaxAbsScaler()),('lgbm', LGBMRegressor(**lgbm_params_1))])),\n",
    "#         ('lgbm-2', Pipeline([('scaler', MaxAbsScaler()),('lgbm', LGBMRegressor(**lgbm_params_2))])),        \n",
    "#         ('xgb-1', Pipeline([('scaler', MaxAbsScaler()),('xgb', XGBRegressor(**xgb_params_1))])),\n",
    "#         ('xgb-2', Pipeline([('scaler', MaxAbsScaler()),('xgb', XGBRegressor(**xgb_params_2))])),\n",
    "        ('gboost', GradientBoostingRegressor(n_estimators=100, \n",
    "                                             learning_rate=0.05, \n",
    "                                             max_depth=7, max_features='sqrt', \n",
    "                                             min_samples_leaf=15, \n",
    "                                             min_samples_split=10, \n",
    "                                             loss='huber', random_state =5)),\n",
    "        ('xtree', ExtraTreesRegressor(n_estimators=200)),\n",
    "        ('lasso', Pipeline([('scaler', MaxAbsScaler()),('xgb', Lasso(alpha =0.0005, random_state=1))])),\n",
    "        ('KRR', KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)),\n",
    "        ('ENet', Pipeline([('scaler', RobustScaler()), ('Eet', ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))])), \n",
    "        ('ridgecv', Pipeline([('scaler', MaxAbsScaler()),('ridgecv', RidgeCV())])),\n",
    "        ('linearsvr', Pipeline([('scaler', MaxAbsScaler()),('svr', LinearSVR())]))\n",
    "    ]\n",
    "\n",
    "    \n",
    "    \n",
    "    # # xtratree = ExtraTreesRegressor(n_estimators=100)\n",
    "# # ridge = make_pipeline(RobustScaler(), RidgeCV())\n",
    "# # lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n",
    "# # SVR = make_pipeline(RobustScaler(), LinearSVR())\n",
    "# # KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n",
    "# # ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n",
    "    \n",
    "    \n",
    "    reg = StackingRegressor(\n",
    "         estimators=estimators,\n",
    "         final_estimator=LinearSVR(random_state=42),\n",
    "         verbose = 10,\n",
    "#          n_jobs = -1\n",
    "    )\n",
    "    \n",
    "#     reg = StackingRegressor(\n",
    "#          estimators=estimators,\n",
    "#          final_estimator=XGBRegressor(random_state=42),\n",
    "#          n_jobs = -1,\n",
    "#          verbose = 10\n",
    "#     )\n",
    "    \n",
    "#     reg = StackingRegressor(\n",
    "#          estimators=estimators,\n",
    "#          final_estimator=RandomForestRegressor(random_state=42),\n",
    "#          verbose = 10, \n",
    "#          n_jobs = -1,\n",
    "#     )\n",
    "    \n",
    "    return reg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b563a07-b720-489c-8f22-826c49ff4704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vmd(y,k):\n",
    "    \n",
    "    #Intrinsic mode generation\n",
    "     #Empirical Mode Decomposition\n",
    "    #. some sample parameters for VMD  \n",
    "    alpha = 1       # moderate bandwidth constraint  \n",
    "    tau = 0.           # noise-tolerance (no strict fidelity enforcement)  \n",
    "    K = k              # k modes  \n",
    "    DC = 0             # no DC part imposed  \n",
    "    init = 1           # initialize omegas uniformly  \n",
    "    tol = 1e-7\n",
    "    u, u_hat, omega = VMD(y,alpha, tau, K, DC, init, tol)\n",
    "    df_vmfs = pd.DataFrame()\n",
    "    #Integration in the dataframe\n",
    "    for num, imf in enumerate(u):\n",
    "        #print('----Creating VMFwp{0} EMD columns----'.format(num+1))\n",
    "        df_vmfs['IMFwp{0}'.format(num+1)] = imf\n",
    "    return df_vmfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae2eb33-a6b7-42a5-9d72-c742afbaedb0",
   "metadata": {},
   "source": [
    "# Data preparation and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dc1d32-9202-4d51-86a7-c246bda4d349",
   "metadata": {},
   "source": [
    "## WP1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39473823-b3c0-4823-945f-82252d0836de",
   "metadata": {},
   "outputs": [],
   "source": [
    "wp1_X = train_wp1[[c for c in train_wp1 if c not in [\"wp\"]] + [\"wp\"]].drop(to_drop, axis = 1)\n",
    "X1 = wp1_X.drop('wp', axis=1)\n",
    "y1 = wp1_X['wp']\n",
    "vmf_1=vmd(y1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa6cd2e4-16bd-40a1-8f3a-a7a074871c4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params_lgbm_1 =   [{\n",
    "    'reg_alpha': 0.25020407037516895,\n",
    "    'reg_lambda': 7.183180037262842,\n",
    "    'colsample_bytree': 1.0,\n",
    "    'subsample': 1.0,\n",
    "    'learning_rate': 0.11751089382716717,\n",
    "    'max_depth': 84,\n",
    "    'num_leaves': 596,\n",
    "    'min_child_samples': 15,\n",
    "}, {\n",
    "    'reg_alpha': 0.8314449043001416,\n",
    "    'reg_lambda': 9.093012403173608,\n",
    "    'colsample_bytree': 0.9,\n",
    "    'subsample': 0.4,\n",
    "    'learning_rate': 0.2033256175102991,\n",
    "    'max_depth': 55,\n",
    "    'num_leaves': 964,\n",
    "    'min_child_samples': 25,\n",
    "}]\n",
    "\n",
    "params_xgb_1 = [{\n",
    "    'lambda': 0.3643806022565838,\n",
    "    'alpha': 0.003650309466012506,\n",
    "    'colsample_bytree': 0.9640425007241273,\n",
    "    'subsample': 0.8,\n",
    "    'learning_rate': 0.052762727588106954,\n",
    "    'n_estimators': 700,\n",
    "    'max_depth': 54,\n",
    "    'min_child_weight': 96,\n",
    "    'eta': 3.119364108002744e-05,\n",
    "    'gamma': 5.177778739056542e-05,\n",
    "    'grow_policy': 'lossguide',\n",
    "}, {\n",
    "    'lambda': 2.1359622347936646,\n",
    "    'alpha': 0.016202766042783825,\n",
    "    'colsample_bytree': 0.8075360516891219,\n",
    "    'subsample': 0.8,\n",
    "    'learning_rate': 0.06792370224097045,\n",
    "    'n_estimators': 320,\n",
    "    'max_depth': 58,\n",
    "    'min_child_weight': 102,\n",
    "    'eta': 6.934521001624072e-05,\n",
    "    'gamma': 4.369012735807193e-06,\n",
    "    'grow_policy': 'lossguide',\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37d762d3-2ed6-4d2a-b0c7-b8ab3037075a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = stacking_model(params_xgb_1[0], params_xgb_1[1], params_lgbm_1[0], params_lgbm_1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8183ce5-1605-439a-88ca-8ca5a6cf1a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------STACKING CROSS VALIDATION BEGINNING-----------\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 16.6 GiB for an array with shape (47174, 47174) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\GERALD~1.CAS\\AppData\\Local\\Temp/ipykernel_7732/3260106565.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstacking_scaled_cross_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmf_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'IMFwp1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\GERALD~1.CAS\\AppData\\Local\\Temp/ipykernel_7732/4144992904.py\u001b[0m in \u001b[0;36mstacking_scaled_cross_validation\u001b[1;34m(X, y, model)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gerald.casterou\\venv\\datachallenge_wp_phase2\\lib\\site-packages\\sklearn\\ensemble\\_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    686\u001b[0m         \"\"\"\n\u001b[0;32m    687\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gerald.casterou\\venv\\datachallenge_wp_phase2\\lib\\site-packages\\sklearn\\ensemble\\_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[1;31m# base estimators will be used in transform, predict, and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m         \u001b[1;31m# predict_proba. They are exposed publicly.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m         self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[0;32m    148\u001b[0m             \u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_fit_single_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_estimators\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mest\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'drop'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gerald.casterou\\venv\\datachallenge_wp_phase2\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gerald.casterou\\venv\\datachallenge_wp_phase2\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gerald.casterou\\venv\\datachallenge_wp_phase2\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gerald.casterou\\venv\\datachallenge_wp_phase2\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gerald.casterou\\venv\\datachallenge_wp_phase2\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gerald.casterou\\venv\\datachallenge_wp_phase2\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gerald.casterou\\venv\\datachallenge_wp_phase2\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gerald.casterou\\venv\\datachallenge_wp_phase2\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\gerald.casterou\\venv\\datachallenge_wp_phase2\\lib\\site-packages\\sklearn\\ensemble\\_base.py\u001b[0m in \u001b[0;36m_fit_single_estimator\u001b[1;34m(estimator, X, y, sample_weight, message_clsname, message)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gerald.casterou\\venv\\datachallenge_wp_phase2\\lib\\site-packages\\sklearn\\kernel_ridge.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    170\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m         \u001b[0mK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_kernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m         \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gerald.casterou\\venv\\datachallenge_wp_phase2\\lib\\site-packages\\sklearn\\kernel_ridge.py\u001b[0m in \u001b[0;36m_get_kernel\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    131\u001b[0m                       \u001b[1;34m\"degree\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m                       \"coef0\": self.coef0}\n\u001b[1;32m--> 133\u001b[1;33m         return pairwise_kernels(X, Y, metric=self.kernel,\n\u001b[0m\u001b[0;32m    134\u001b[0m                                 filter_params=True, **params)\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gerald.casterou\\venv\\datachallenge_wp_phase2\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gerald.casterou\\venv\\datachallenge_wp_phase2\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_kernels\u001b[1;34m(X, Y, metric, filter_params, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1952\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown kernel %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1953\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1954\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\gerald.casterou\\venv\\datachallenge_wp_phase2\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1359\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m     \u001b[1;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gerald.casterou\\venv\\datachallenge_wp_phase2\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpolynomial_kernel\u001b[1;34m(X, Y, degree, gamma, coef0)\u001b[0m\n\u001b[0;32m   1035\u001b[0m         \u001b[0mgamma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m     \u001b[0mK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m     \u001b[0mK\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m     \u001b[0mK\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gerald.casterou\\venv\\datachallenge_wp_phase2\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gerald.casterou\\venv\\datachallenge_wp_phase2\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    150\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 16.6 GiB for an array with shape (47174, 47174) and data type float64"
     ]
    }
   ],
   "source": [
    "stacking_scaled_cross_validation(X1, vmf_1['IMFwp1'], model_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6022a2f2-47bf-471c-9434-af2b39ea2429",
   "metadata": {},
   "source": [
    "## WP2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f706b351-afe7-4d9e-bbb5-d8e0360ab5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "wp2_X = train_wp2[[c for c in train_wp2 if c not in [\"wp\"]] + [\"wp\"]].drop(to_drop, axis = 1)\n",
    "X2 = wp2_X.drop('wp', axis=1)\n",
    "y2 = wp2_X['wp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "575cf4a3-88ca-45ad-b0e0-387e4f99804d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params_lgbm_2 =   [{\n",
    "    'reg_alpha': 0.18268883436586145,\n",
    "    'reg_lambda': 0.15916821051528962,\n",
    "    'colsample_bytree': 1.0,\n",
    "    'subsample': 0.6,\n",
    "    'learning_rate': 0.18007000714755378,\n",
    "    'max_depth': 77,\n",
    "    'num_leaves': 425,\n",
    "    'min_child_samples': 10,\n",
    "    'min_data_per_groups': 19,\n",
    "}, {\n",
    "    'reg_alpha': 0.34026994469471555,\n",
    "    'reg_lambda': 1.1032197453137866,\n",
    "    'colsample_bytree': 0.9,\n",
    "    'subsample': 0.6,\n",
    "    'learning_rate': 0.13414826176962302,\n",
    "    'max_depth': 81,\n",
    "    'num_leaves': 987,\n",
    "    'min_child_samples': 39,\n",
    "}]\n",
    "\n",
    "params_xgb_2 = [{\n",
    "    'lambda': 0.005195058020286749,\n",
    "    'alpha': 0.15427340616771562,\n",
    "    'colsample_bytree': 0.4794118698886291,\n",
    "    'subsample': 0.7,\n",
    "    'learning_rate': 0.13969003989794868,\n",
    "    'n_estimators': 583,\n",
    "    'max_depth': 20,\n",
    "    'min_child_weight': 81,\n",
    "    'eta': 0.0006994052800675432,\n",
    "    'gamma': 4.0927842177131904e-08,\n",
    "    'grow_policy': 'depthwise',\n",
    "}, {\n",
    "    'lambda': 4.982427302967441,\n",
    "    'alpha': 0.023879453147379343,\n",
    "    'colsample_bytree': 0.29850970311481473,\n",
    "    'subsample': 0.7,\n",
    "    'learning_rate': 0.07986759823219342,\n",
    "    'n_estimators': 634,\n",
    "    'max_depth': 52,\n",
    "    'min_child_weight': 142,\n",
    "    'eta': 0.9698508070965183,\n",
    "    'gamma': 6.168834828494383e-06,\n",
    "    'grow_policy': 'depthwise',\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f68707cc-224a-4f75-b5f5-f054e40a3959",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = stacking_model(params_xgb_2[0], params_xgb_2[1], params_lgbm_2[0], params_lgbm_2[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2d4dc5-2f59-4184-83cb-dbb4951975c9",
   "metadata": {},
   "source": [
    "## WP3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5163d5b8-ea9c-4c3a-9014-9b15f541925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wp3_X = train_wp3[[c for c in train_wp3 if c not in [\"wp\"]] + [\"wp\"]].drop(to_drop, axis = 1)\n",
    "X3 = wp3_X.drop('wp', axis = 1)\n",
    "y3 = wp3_X['wp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef277fd5-a26e-4004-afd8-97e6120d034e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params_lgbm_3 = [{\n",
    "    'reg_alpha': 0.2380367567801365,\n",
    "    'reg_lambda': 0.005052844767806766,\n",
    "    'colsample_bytree': 0.9,\n",
    "    'subsample': 0.5,\n",
    "    'learning_rate': 0.11958787026894079,\n",
    "    'max_depth': 41,\n",
    "    'num_leaves': 690,\n",
    "}, {\n",
    "    'reg_alpha': 0.26013926149282945,\n",
    "    'reg_lambda': 0.002325658512162904,\n",
    "    'colsample_bytree': 1.0,\n",
    "    'subsample': 0.7,\n",
    "    'learning_rate': 0.10619054458258967,\n",
    "    'max_depth': 83,\n",
    "    'num_leaves': 647,\n",
    "    'min_child_samples': 3,\n",
    "}]   \n",
    "    \n",
    "params_xgb_3 = [{\n",
    "    'lambda': 0.018191871915246106,\n",
    "    'alpha': 0.2397827070234125,\n",
    "    'colsample_bytree': 0.4710946041352672,\n",
    "    'subsample': 0.8,\n",
    "    'learning_rate': 0.14812785561924302,\n",
    "    'n_estimators': 688,\n",
    "    'max_depth': 32,\n",
    "    'min_child_weight': 218,\n",
    "    'eta': 6.950960910550952e-08,\n",
    "    'gamma': 2.0149702062428016e-07,\n",
    "    'grow_policy': 'lossguide',\n",
    "}, {\n",
    "    'lambda': 0.018191871915246106,\n",
    "    'alpha': 0.2397827070234125,\n",
    "    'colsample_bytree': 0.4710946041352672,\n",
    "    'subsample': 0.9,\n",
    "    'learning_rate': 0.11812785561924302,\n",
    "    'n_estimators': 400,\n",
    "    'max_depth': 28,\n",
    "    'min_child_weight': 220,\n",
    "    'eta': 6.950960910550952e-08,\n",
    "    'gamma': 2.0149702062428016e-07,\n",
    "    'grow_policy': 'lossguide',\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "671ea812-5ac9-42de-a83c-54b3426090c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = stacking_model(params_xgb_3[0], params_xgb_3[1], params_lgbm_3[0], params_lgbm_3[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273f92bf-cd57-4163-90ab-c4e98c88aa0a",
   "metadata": {},
   "source": [
    "## WP4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84673a7f-5192-451e-b1e7-c6f8046deb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "wp4_X = train_wp4[[c for c in train_wp4 if c not in [\"wp\"]] + [\"wp\"]].drop(to_drop, axis = 1)\n",
    "X4 = wp4_X.drop('wp', axis = 1)\n",
    "y4 = wp4_X['wp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56dfeafa-025c-487d-9844-318c8a11cc6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params_lgbm_4 = [{\n",
    "    'reg_alpha': 0.08714703614419553,\n",
    "    'reg_lambda': 9.983645262139024,\n",
    "    'colsample_bytree': 0.9,\n",
    "    'subsample': 0.8,\n",
    "    'learning_rate': 0.13413154768816146,\n",
    "    'max_depth': 41,\n",
    "    'num_leaves': 613,\n",
    "    'min_child_samples': 15,\n",
    "}, {\n",
    "    'reg_alpha': 0.15331128149569725,\n",
    "    'reg_lambda': 0.28560184971009756,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'subsample': 0.5,\n",
    "    'learning_rate': 0.11430869527789024,\n",
    "    'max_depth': 24,\n",
    "    'num_leaves': 856,\n",
    "    'min_child_samples': 14,\n",
    "}]\n",
    "\n",
    "params_xgb_4 = [{\n",
    "    'lambda': 0.13763482520556616,\n",
    "    'alpha': 0.0010077676339636944,\n",
    "    'colsample_bytree': 0.954734556572597,\n",
    "    'subsample': 0.8,\n",
    "    'learning_rate': 0.05499114408834853,\n",
    "    'n_estimators': 546,\n",
    "    'max_depth': 43,\n",
    "    'min_child_weight': 94,\n",
    "    'eta': 1.2784286267654713e-06,\n",
    "    'gamma': 1.6935174502873177e-05,\n",
    "    'grow_policy': 'depthwise',\n",
    "}, {\n",
    "    'lambda': 0.001340947773207149,\n",
    "    'alpha': 0.002479638085657274,\n",
    "    'colsample_bytree': 0.3030181981060389,\n",
    "    'subsample': 0.7,\n",
    "    'learning_rate': 0.07696248319007938,\n",
    "    'n_estimators': 367,\n",
    "    'max_depth': 31,\n",
    "    'min_child_weight': 72,\n",
    "    'eta': 3.704957186572025e-08,\n",
    "    'gamma': 8.44315434172209e-05,\n",
    "    'grow_policy': 'depthwise',\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0fc87d25-870c-4f5b-ac4b-6c5b88b89ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4 = stacking_model(params_xgb_4[0], params_xgb_4[1], params_lgbm_4[0], params_lgbm_4[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb8967b-d516-487d-9a5f-1bdf5d965d41",
   "metadata": {},
   "source": [
    "## WP5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f711b6de-c37a-4af2-86ec-2058d155234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wp5_X = train_wp5[[c for c in train_wp5 if c not in [\"wp\"]] + [\"wp\"]].drop(to_drop, axis = 1)\n",
    "X5 = wp5_X.drop('wp', axis = 1)\n",
    "y5 = wp5_X['wp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f048dba3-0231-4aeb-8aaa-d554594605ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params_lgbm_5 = [{\n",
    "    'reg_alpha': 0.1420112281892889,\n",
    "    'reg_lambda': 0.14745955581286027,\n",
    "    'colsample_bytree': 0.9,\n",
    "    'subsample': 0.7,\n",
    "    'learning_rate': 0.15576554024588912,\n",
    "    'max_depth': 61,\n",
    "    'num_leaves': 483,\n",
    "    'min_child_samples': 10,\n",
    "}, {\n",
    "    'reg_alpha': 0.04781362061382749,\n",
    "    'reg_lambda': 9.716980953182604,\n",
    "    'colsample_bytree': 0.9,\n",
    "    'subsample': 0.7,\n",
    "    'learning_rate': 0.14614317149730652,\n",
    "    'max_depth': 57,\n",
    "    'num_leaves': 532,\n",
    "    'min_child_samples': 7,\n",
    "}]\n",
    "\n",
    "\n",
    "params_xgb_5 = [{\n",
    "    'lambda': 4.7653031074423104,\n",
    "    'alpha': 0.004963619239675007,\n",
    "    'colsample_bytree': 0.8616303151950829,\n",
    "    'subsample': 0.8,\n",
    "    'learning_rate': 0.167247240657064,\n",
    "    'n_estimators': 509,\n",
    "    'max_depth': 31,\n",
    "    'min_child_weight': 73,\n",
    "    'eta': 0.1392993925005545,\n",
    "    'gamma': 1.4909263616645174e-07,\n",
    "    'grow_policy': 'depthwise',\n",
    "}, {\n",
    "    'lambda': 4.537995153532639,\n",
    "    'alpha': 0.15887083612902936,\n",
    "    'colsample_bytree': 0.35129085402309673,\n",
    "    'subsample': 0.8,\n",
    "    'learning_rate': 0.20146110291550628,\n",
    "    'n_estimators': 354,\n",
    "    'max_depth': 27,\n",
    "    'min_child_weight': 91,\n",
    "    'eta': 0.1963402390178624,\n",
    "    'gamma': 4.730295821405375e-07,\n",
    "    'grow_policy': 'lossguide',\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21b613da-05d5-4c00-a4c4-fcc0336fc586",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5 = stacking_model(params_xgb_5[0], params_xgb_5[1], params_lgbm_5[0], params_lgbm_5[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d5b1f0-9cbc-4b4d-80bb-2fcbb5a2a138",
   "metadata": {},
   "source": [
    "## WP6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "038868ba-c901-4e9a-b4d1-cd59bbb32a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wp6_X = train_wp6[[c for c in train_wp6 if c not in [\"wp\"]] + [\"wp\"]].drop(to_drop, axis = 1)\n",
    "X6 = wp6_X.drop('wp', axis = 1)\n",
    "y6 = wp6_X['wp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06f05bae-cf5d-4f74-89ab-28d9aaafee64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params_lgbm_6 = [{\n",
    "    'reg_alpha': 0.19099691249064502,\n",
    "    'reg_lambda': 0.3893771552082417,\n",
    "    'colsample_bytree': 0.6,\n",
    "    'subsample': 0.7,\n",
    "    'learning_rate': 0.10214699989265669,\n",
    "    'max_depth': 70,\n",
    "    'num_leaves': 903,\n",
    "    'min_child_samples': 1,\n",
    "}, {\n",
    "    'reg_alpha': 0.23451110075396234,\n",
    "    'reg_lambda': 0.796705483623135,\n",
    "    'colsample_bytree': 0.9,\n",
    "    'subsample': 0.4,\n",
    "    'learning_rate': 0.1561492653707781,\n",
    "    'max_depth': 67,\n",
    "    'num_leaves': 998,\n",
    "    'min_child_samples': 45,\n",
    "}]\n",
    "\n",
    "params_xgb_6 = [{\n",
    "    'lambda': 6.198890709955999,\n",
    "    'alpha': 0.009212761583335095,\n",
    "    'colsample_bytree': 0.9364947872025757,\n",
    "    'subsample': 0.6,\n",
    "    'learning_rate': 0.0377294321765545,\n",
    "    'n_estimators': 458,\n",
    "    'max_depth': 50,\n",
    "    'min_child_weight': 28,\n",
    "    'eta': 1.0671149195024988e-08,\n",
    "    'gamma': 1.4697758952551594e-05,\n",
    "    'grow_policy': 'depthwise',\n",
    "}, {\n",
    "    'lambda': 0.5705269295320163,\n",
    "    'alpha': 0.06713843687958011,\n",
    "    'colsample_bytree': 0.8718486759988152,\n",
    "    'subsample': 0.8,\n",
    "    'learning_rate': 0.07668854905667996,\n",
    "    'n_estimators': 582,\n",
    "    'max_depth': 49,\n",
    "    'min_child_weight': 143,\n",
    "    'eta': 9.055710235537663e-07,\n",
    "    'gamma': 1.111486195598291e-06,\n",
    "    'grow_policy': 'depthwise',\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "430eab5b-b681-4093-805d-441e9814cfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6 = stacking_model(params_xgb_6[0], params_xgb_6[1], params_lgbm_6[0], params_lgbm_6[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f798f81-9f98-4889-806d-c3fd68503df0",
   "metadata": {},
   "source": [
    "# Super learner ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec83c430-c3eb-45c7-9259-5d33ba69ece1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Stacking of multiple models\n",
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=6):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            print(f\"-----Model {i}----\")\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) \n",
    "            for model in base_models]).mean(axis=1) \n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea8bca6-c778-434d-a223-8ca986547e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking of one model\n",
    "class StackingSL_1Model(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_model, meta_model, n_folds=6):\n",
    "        self.base_model = base_model\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = []\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        \n",
    "        \n",
    "        for train_index, holdout_index in kfold.split(X, y):\n",
    "            instance = clone(model)\n",
    "            self.base_models_[i].append(instance)\n",
    "            instance.fit(X[train_index], y[train_index])\n",
    "            y_pred = instance.predict(X[holdout_index])\n",
    "            out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) \n",
    "            for model in base_models]).mean(axis=1) \n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfc0c35-727f-4a86-9249-ab6831764939",
   "metadata": {},
   "source": [
    "## Used model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca05de9e-06b1-452f-b54d-6629ee94af33",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # xtratree = ExtraTreesRegressor(n_estimators=100)\n",
    "# # ridge = make_pipeline(RobustScaler(), RidgeCV())\n",
    "# # lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n",
    "# # SVR = make_pipeline(RobustScaler(), LinearSVR())\n",
    "# # KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n",
    "# # ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n",
    "# # GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "# #                                    max_depth=4, max_features='sqrt',\n",
    "# #                                    min_samples_leaf=15, min_samples_split=10, \n",
    "# #                                    loss='huber', random_state =5)\n",
    "\n",
    "# xtratrees = ExtraTreesRegressor(n_estimators=100) \n",
    "# ridgecv = Pipeline([('scaler', MaxAbsScaler()),('ridgecv', RidgeCV())])\n",
    "# linearsvr = Pipeline([('scaler', MaxAbsScaler()),('svr', LinearSVR())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e8070b13-5999-4974-a8a3-05e200929d4b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def rmsle_cv(model, X, y):\n",
    "#     kf = KFold(2, shuffle=True, random_state=42).get_n_splits(X)\n",
    "#     rmse= np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "#     return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "baeb50a6-f005-41c5-95d3-fbdb4d24a835",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lgbm_a_1 = Pipeline([('scaler', MaxAbsScaler()),('lgbm', LGBMRegressor(**params_lgbm_1))])\n",
    "# lgbm_b_1 = Pipeline([('scaler', MaxAbsScaler()),('lgbm', LGBMRegressor(**params_lgbm_1_bis))])\n",
    "# xgb_a_1 = Pipeline([('scaler', MaxAbsScaler()),('xgb', XGBRegressor(**params_xgb_1))])\n",
    "# xgb_b_1 =Pipeline([('scaler', MaxAbsScaler()),('xgb', XGBRegressor(**params_xgb_1_bis))])\n",
    "\n",
    "# lgbm_a_2 = Pipeline([('scaler', MaxAbsScaler()),('lgbm', LGBMRegressor(**params_lgbm_2))])\n",
    "# lgbm_b_2 = Pipeline([('scaler', MaxAbsScaler()),('lgbm', LGBMRegressor(**params_lgbm_2_bis))])\n",
    "# xgb_a_2 = Pipeline([('scaler', MaxAbsScaler()),('xgb', XGBRegressor(**params_xgb_2))])\n",
    "# xgb_b_2 =Pipeline([('scaler', MaxAbsScaler()),('xgb', XGBRegressor(**params_xgb_2_bis))])\n",
    "\n",
    "# lgbm_a_3 = Pipeline([('scaler', MaxAbsScaler()),('lgbm', LGBMRegressor(**params_lgbm_3))])\n",
    "# lgbm_b_3 = Pipeline([('scaler', MaxAbsScaler()),('lgbm', LGBMRegressor(**params_lgbm_3_bis))])\n",
    "# xgb_a_3 = Pipeline([('scaler', MaxAbsScaler()),('xgb', XGBRegressor(**params_xgb_3))])\n",
    "# xgb_b_3 =Pipeline([('scaler', MaxAbsScaler()),('xgb', XGBRegressor(**params_xgb_3_bis))])\n",
    "\n",
    "# lgbm_a_4 = Pipeline([('scaler', MaxAbsScaler()),('lgbm', LGBMRegressor(**params_lgbm_4))])\n",
    "# lgbm_b_4 = Pipeline([('scaler', MaxAbsScaler()),('lgbm', LGBMRegressor(**params_lgbm_4_bis))])\n",
    "# xgb_a_4 = Pipeline([('scaler', MaxAbsScaler()),('xgb', XGBRegressor(**params_xgb_4))])\n",
    "# xgb_b_4 =Pipeline([('scaler', MaxAbsScaler()),('xgb', XGBRegressor(**params_xgb_4_bis))])\n",
    "\n",
    "# lgbm_a_5 = Pipeline([('scaler', MaxAbsScaler()),('lgbm', LGBMRegressor(**params_lgbm_5))])\n",
    "# lgbm_b_5 = Pipeline([('scaler', MaxAbsScaler()),('lgbm', LGBMRegressor(**params_lgbm_5_bis))])\n",
    "# xgb_a_5 = Pipeline([('scaler', MaxAbsScaler()),('xgb', XGBRegressor(**params_xgb_5))])\n",
    "# xgb_b_5 =Pipeline([('scaler', MaxAbsScaler()),('xgb', XGBRegressor(**params_xgb_5_bis))])\n",
    "\n",
    "# lgbm_a_6 = Pipeline([('scaler', MaxAbsScaler()),('lgbm', LGBMRegressor(**params_lgbm_6))])\n",
    "# lgbm_b_6 = Pipeline([('scaler', MaxAbsScaler()),('lgbm', LGBMRegressor(**params_lgbm_6_bis))])\n",
    "# xgb_a_6 = Pipeline([('scaler', MaxAbsScaler()),('xgb', XGBRegressor(**params_xgb_6))])\n",
    "# xgb_b_6 =Pipeline([('scaler', MaxAbsScaler()),('xgb', XGBRegressor(**params_xgb_6_bis))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fa000723-8204-490d-beed-fc96133ab0fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_1 = StackingAveragedModels(base_models = (lgbm_a_1, lgbm_a_1, lgbm_a_1, lgbm_a_1, lgbm_a_1), meta_model = RidgeCV(), n_folds=10)\n",
    "# model_2 = StackingAveragedModels(base_models = (lgbm_a_2, lgbm_b_2, xgb_a_2, xgb_b_2, xtratrees, ridgecv, linearsvr), meta_model = RidgeCV(), n_folds=5)\n",
    "# model_3 = StackingAveragedModels(base_models = (lgbm_a_3, lgbm_b_3, xgb_a_3, xgb_b_3, xtratrees, ridgecv, linearsvr), meta_model = RidgeCV(), n_folds=5)\n",
    "# model_4 = StackingAveragedModels(base_models = (lgbm_a_4, lgbm_b_4, xgb_a_4, xgb_b_4, xtratrees, ridgecv, linearsvr), meta_model = RidgeCV(), n_folds=5)\n",
    "# model_5 = StackingAveragedModels(base_models = (lgbm_a_5, lgbm_b_5, xgb_a_5, xgb_b_5, xtratrees, ridgecv, linearsvr), meta_model = RidgeCV(), n_folds=5)\n",
    "# model_6 = StackingAveragedModels(base_models = (lgbm_a_6, lgbm_b_6, xgb_a_6, xgb_b_6, xtratrees, ridgecv, linearsvr), meta_model = RidgeCV(), n_folds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0905a9-40eb-4356-a6d6-f94184795224",
   "metadata": {},
   "source": [
    "# Predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab4a8367-cf20-4315-afec-7f79878102e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop_test = ['date','wd','forecast_time', 'forecast', \"forecast_dist\", 'wp']\n",
    "def make_prediction_dataset(test, to_drop=to_drop_test):\n",
    "    test_to_predict = test.dropna(subset=['ws','u','v'], how = 'any') # keeps only lines with u,v,ws,wd\n",
    "    test_to_predict = test_to_predict[test_to_predict['wp'].isna()] # keeps only lines with no wp\n",
    "    test_to_predict = test_to_predict.sort_values(by=['date', 'forecast_time'], ascending = [True, False]).drop_duplicates(subset='date')\n",
    "    test_to_predict = test_to_predict.drop(to_drop, axis = 1)\n",
    "    return test_to_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "787439b7-6c92-42ef-b540-cda0dc986fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission_file(lst_X_trains, lst_y_trains, lst_tests, lst_models, dates):\n",
    "    i = 1\n",
    "    lst_prediction = []\n",
    "    lst_models_trained = []\n",
    "    for X, y, test, model in zip(lst_X_trains, lst_y_trains, lst_tests, lst_models):\n",
    "        print(f'--------------Dataset {i}--------------')\n",
    "        X = X.to_numpy()\n",
    "        y = y.to_numpy()\n",
    "        test = test.to_numpy()\n",
    "        model.fit(X, y)\n",
    "        print(f'True:\\n\\tMin:{min(y)}\\n\\tMax:{max(y)}\\n\\tMean:{y.mean()}')\n",
    "        predictions = model.predict(test)\n",
    "        print(f'Prediction:\\n\\tMin:{min(predictions)}\\n\\tMax:{max(predictions)}\\n\\tMean:{np.mean(predictions)}')\n",
    "        predictions = [min(y) if i < 0 else i for i in predictions]\n",
    "        predictions = [max(y) if i > max(y) else i for i in predictions]\n",
    "        print(f'Prediction corrected:\\n\\tMin:{min(predictions)}\\n\\tMax:{max(predictions)}\\n\\tMean:{np.mean(predictions)}')\n",
    "        lst_prediction.append(predictions)\n",
    "        lst_models_trained.append(model)\n",
    "        i+=1\n",
    "    \n",
    "    df_predictions = pd.DataFrame({\n",
    "        'date': test_dates,\n",
    "        'wp1': lst_prediction[0],\n",
    "        'wp2': lst_prediction[1],\n",
    "        'wp3': lst_prediction[2],\n",
    "        'wp4': lst_prediction[3],\n",
    "        'wp5': lst_prediction[4],\n",
    "        'wp6': lst_prediction[5],        \n",
    "    })\n",
    "    return df_predictions, lst_models_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4e500e68-a4c6-493c-87ab-bbab9199f27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_models = [model_1, model_2, model_3, model_4, model_5, model_6]\n",
    "lst_X_trains = [X1, X2, X3, X4, X5, X6]\n",
    "lst_y_trains = [y1, y2, y3, y4, y5, y6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a60d7dcd-85e7-4d07-990b-7b17cd2010e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_tests = []\n",
    "for test in [test_wp1, test_wp2, test_wp3, test_wp4, test_wp5, test_wp6]:\n",
    "    test = make_prediction_dataset(test)\n",
    "    lst_tests.append(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becbb508-0320-4a9c-a7dd-05db21988b62",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "26d8d32a-6e49-4bc8-b7c3-cb0e26082de3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------Dataset 1--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 17.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 34.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 50.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 67.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 83.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 83.5min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  6.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 13.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 20.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 27.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 34.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 34.7min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   15.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   23.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   31.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   39.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   39.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 10.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 20.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 30.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 39.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 49.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 49.1min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   11.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   21.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   32.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   42.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   53.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   53.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    5.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    6.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    8.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    8.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   24.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   48.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  1.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  1.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True:\n",
      "\tMin:0.0\n",
      "\tMax:0.96\n",
      "\tMean:0.2845981952075702\n",
      "Prediction:\n",
      "\tMin:-0.030387654738908663\n",
      "\tMax:1.0710022895516644\n",
      "\tMean:0.2978373449945766\n",
      "Prediction corrected:\n",
      "\tMin:0.0\n",
      "\tMax:0.96\n",
      "\tMean:0.2984618040749219\n",
      "--------------Dataset 2--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 16.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 32.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 48.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 65.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 81.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 81.2min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  7.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 14.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 21.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 29.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 36.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 36.3min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   13.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   19.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   27.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   31.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   31.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 10.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 20.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 29.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 39.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 48.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 48.8min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   11.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   20.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   30.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   41.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   51.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   51.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    5.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    6.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    8.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    8.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   23.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   47.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  1.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  1.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True:\n",
      "\tMin:0.0\n",
      "\tMax:0.966\n",
      "\tMean:0.25890153769841273\n",
      "Prediction:\n",
      "\tMin:-0.051401744488862804\n",
      "\tMax:0.977216853697399\n",
      "\tMean:0.2415722699522402\n",
      "Prediction corrected:\n",
      "\tMin:0.0\n",
      "\tMax:0.966\n",
      "\tMean:0.24212177774338323\n",
      "--------------Dataset 3--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 16.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 32.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 48.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 64.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 80.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 80.8min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  7.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 14.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 21.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 28.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 35.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 35.1min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    8.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   14.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   19.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   23.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   23.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 11.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 21.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 31.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 40.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 50.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 50.9min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   18.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   27.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   38.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   47.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   47.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    5.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    7.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    9.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    9.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   25.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   50.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  1.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  1.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True:\n",
      "\tMin:0.0\n",
      "\tMax:0.989\n",
      "\tMean:0.2625247252747253\n",
      "Prediction:\n",
      "\tMin:-0.05402813628325692\n",
      "\tMax:1.1609366763403686\n",
      "\tMean:0.2827977314362653\n",
      "Prediction corrected:\n",
      "\tMin:0.0\n",
      "\tMax:0.989\n",
      "\tMean:0.2834158511642645\n",
      "--------------Dataset 4--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 16.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 32.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 48.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 65.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 81.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 81.5min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  7.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 14.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 21.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 28.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 36.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 36.3min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   14.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   21.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   29.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   36.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   36.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 10.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 20.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 30.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 40.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 49.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 49.8min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   21.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   31.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   40.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   51.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   51.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    5.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    6.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    8.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    8.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   23.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   47.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  1.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  1.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True:\n",
      "\tMin:0.0\n",
      "\tMax:0.992\n",
      "\tMean:0.2763637820512821\n",
      "Prediction:\n",
      "\tMin:-0.05196724211457392\n",
      "\tMax:1.0412599681581043\n",
      "\tMean:0.2834744861676652\n",
      "Prediction corrected:\n",
      "\tMin:0.0\n",
      "\tMax:0.992\n",
      "\tMean:0.2851371106669493\n",
      "--------------Dataset 5--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 16.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 32.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 50.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 67.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 83.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 83.9min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  7.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 14.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 21.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 28.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 35.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 35.2min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   15.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   22.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   30.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   38.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   38.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 10.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 20.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 31.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 44.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 55.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 55.9min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   11.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   22.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   32.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   43.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   54.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   54.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    5.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    7.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    8.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    8.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   22.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   45.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  1.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  1.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True:\n",
      "\tMin:0.0\n",
      "\tMax:0.978\n",
      "\tMean:0.32622119200244204\n",
      "Prediction:\n",
      "\tMin:-0.058406840100628785\n",
      "\tMax:1.0818159999649244\n",
      "\tMean:0.33969518396240067\n",
      "Prediction corrected:\n",
      "\tMin:0.0\n",
      "\tMax:0.978\n",
      "\tMean:0.3393782859311205\n",
      "--------------Dataset 6--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 16.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 33.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 49.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 71.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 94.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 94.6min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 10.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 20.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 30.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 40.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 51.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 51.1min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   10.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   16.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   27.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   31.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   31.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 15.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 30.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 41.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 51.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 61.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 61.9min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   17.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   23.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   32.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   38.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   38.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    5.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    7.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    8.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    8.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   24.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   49.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  1.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  1.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True:\n",
      "\tMin:0.0\n",
      "\tMax:0.947\n",
      "\tMean:0.2425176472832723\n",
      "Prediction:\n",
      "\tMin:-0.05182612954566682\n",
      "\tMax:1.0326131930789462\n",
      "\tMean:0.23148321664565236\n",
      "Prediction corrected:\n",
      "\tMin:0.0\n",
      "\tMax:0.947\n",
      "\tMean:0.2322190249677836\n"
     ]
    }
   ],
   "source": [
    "df_predictions, lst_models_trained = make_submission_file(lst_X_trains, lst_y_trains, lst_tests, lst_models, test_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1bddcaf4-3b78-4794-8260-415f8f37871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_sub = 31\n",
    "model = \"blending_stacking\"\n",
    "lvl0 = \"0-GBoost-RidgeCV-LinearSVR-ExtraTrees-KRR-ENet\"\n",
    "lvl1 = \"1-LinearSVR\"\n",
    "prepro = 'MaxAbs for all'\n",
    "postpro = \"Prediction limited by X_train min&max\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e4e8d0d3-e657-4682-b2a5-9268f92be5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions.to_csv(f'Predictions/submission_nb_{nb_sub}_{model}_{lvl0}_{lvl1}.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0a0c6290-64a3-4e21-a045-d8b9df7fac7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f = open(f\"Predictions/submission-{nb_sub}_{model}_{lvl0}_{lvl1}.txt\", \"x\")\n",
    "# f.write(f\"params_lgbm_1 = {str(params_lgbm_1)}\\nparams_xgb_1 = {str(params_xgb_1)}\\n\")\n",
    "# f.write(f\"params_lgbm_1_bis = {str(params_lgbm_1_bis)}\\nparams_xgb_1_bis = {str(params_xgb_1_bis)}\\n\\n\")\n",
    "# f.write(f\"params_lgbm_2 = {str(params_lgbm_2)}\\nparams_xgb_2 = {str(params_xgb_2)}\\n\")\n",
    "# f.write(f\"params_lgbm_2_bis = {str(params_lgbm_2_bis)}\\nparams_xgb_2_bis = {str(params_xgb_2_bis)}\\n\\n\")\n",
    "# f.write(f\"params_lgbm_3 = {str(params_lgbm_3)}\\nparams_xgb_3 = {str(params_xgb_3)}\\n\")\n",
    "# f.write(f\"params_lgbm_3_bis = {str(params_lgbm_3_bis)}\\nparams_xgb_3_bis = {str(params_xgb_3_bis)}\\n\\n\")\n",
    "# f.write(f\"params_lgbm_4 = {str(params_lgbm_4)}\\nparams_xgb_4 = {str(params_xgb_4)}\\n\")\n",
    "# f.write(f\"params_lgbm_4_bis = {str(params_lgbm_4_bis)}\\nparams_xgb_4_bis = {str(params_xgb_4_bis)}\\n\\n\")\n",
    "# f.write(f\"params_lgbm_5 = {str(params_lgbm_5)}\\nparams_xgb_5 = {str(params_xgb_5)}\\n\")\n",
    "# f.write(f\"params_lgbm_5_bis = {str(params_lgbm_5_bis)}\\nparams_xgb_5_bis = {str(params_xgb_5_bis)}\\n\\n\")\n",
    "# f.write(f\"params_lgbm_6 = {str(params_lgbm_6)}\\nparams_xgb_6 = {str(params_xgb_6)}\\n\")\n",
    "# f.write(f\"params_lgbm_6_bis = {str(params_lgbm_6_bis)}\\nparams_xgb_6_bis = {str(params_xgb_6_bis)}\\n\\n\")\n",
    "\n",
    "f.write(\"Level 0 estimators:\")\n",
    "\n",
    "f.write(\"('gboost', GradientBoostingRegressor(n_estimators=3000,\\nlearning_rate=0.05,\\nmax_depth=4, max_features='sqrt',\\nmin_samples_leaf=15, \\nmin_samples_split=10, \\nloss='huber', random_state =5)),\\n\\n('xtree', ExtraTreesRegressor(n_estimators=100)),\\n('lasso', Pipeline([('scaler', MaxAbsScaler()),('xgb', Lasso(alpha =0.0005, random_state=1))])),\\n('KRR', KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)),\\n('ENet', Pipeline([('scaler', RobustScaler()), ('Eet', ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))])),\\n('ridgecv', Pipeline([('scaler', MaxAbsScaler()),('ridgecv', RidgeCV())])),\\n('linearsvr', Pipeline([('scaler', MaxAbsScaler()),('svr', LinearSVR())]))\\n\")\n",
    "# f.write(f\"xtratree = ExtraTreesRegressor(n_estimators=100)\\n ridge = make_pipeline(RobustScaler(), RidgeCV())\\n lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\\n SVR = make_pipeline(RobustScaler(), LinearSVR())\\n KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\\n ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\\n GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\\nmax_depth=4, max_features='sqrt',\\nmin_samples_leaf=15, min_samples_split=10, \\nloss='huber', random_state =5)\\n\")\n",
    "# f.write(f\"2 lgbm and 2 xgboost with parameters above and MaxAbsScaler.\\ntratrees = ExtraTreesRegressor(n_estimators=100)\\nridgecv = Pipeline([('scaler', MaxAbsScaler()),('ridgecv', RidgeCV())])\\nlinearsvr = Pipeline([('scaler', MaxAbsScaler()),('svr', LinearSVR())])\")\n",
    "\n",
    "# f.write(f\"Preprocessing: {prepro}\\n\")\n",
    "# f.write(f\"Postprocessing: {postpro}\\n\")\n",
    "\n",
    "f.write(f\"Level1 estimator: {lvl1}\\n\")\n",
    "f.write(f\"Models under the name: {model}_{lvl0}_{lvl1}\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdf7692-020d-43d9-a644-0c28ddf87e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_model = f\"Models/Stacking/model_1-{model}_{lvl0}_{lvl1}.pkl\"\n",
    "with open(pkl_model, 'wb') as file:\n",
    "    pickle.dump(lst_models_trained[0], file)\n",
    "    \n",
    "    \n",
    "pkl_model = f\"Models/Stacking/model_2-{model}_{lvl0}_{lvl1}.pkl\"\n",
    "with open(pkl_model, 'wb') as file:\n",
    "    pickle.dump(lst_models_trained[1], file)\n",
    "    \n",
    "\n",
    "pkl_model = f\"Models/Stacking/model_3-{model}_{lvl0}_{lvl1}.pkl\"\n",
    "with open(pkl_model, 'wb') as file:\n",
    "    pickle.dump(lst_models_trained[2], file)\n",
    "\n",
    "\n",
    "pkl_model = f\"Models/Stacking/model_4-{model}_{lvl0}_{lvl1}.pkl\"\n",
    "with open(pkl_model, 'wb') as file:\n",
    "    pickle.dump(lst_models_trained[3], file)\n",
    "\n",
    "\n",
    "pkl_model = f\"Models/Stacking/model_5-{model}_{lvl0}_{lvl1}.pkl\"\n",
    "with open(pkl_model, 'wb') as file:\n",
    "    pickle.dump(lst_models_trained[4], file)\n",
    "\n",
    "\n",
    "pkl_model = f\"Models/Stacking/model_6-{model}_{lvl0}_{lvl1}.pkl\"\n",
    "with open(pkl_model, 'wb') as file:\n",
    "    pickle.dump(lst_models_trained[5], file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
