{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on fait nos modèles et prédictions. Le mieux c'est de faire des parties par modèles je pense ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut aussi qu'on trouve un nomenclature pour les modèles si on les enregistre, afin de garder en tête les différents résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import openpyxl\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold, train_test_split\n",
    "# from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# from xgboost import XGBRegressor\n",
    "# import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Functions.helper_functions import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wp1 = pd.read_csv('Data/Preprocessing/WP1_train_preprocessed.csv', sep=',')\n",
    "train_wp2 = pd.read_csv('Data/Preprocessing/WP2_train_preprocessed.csv', sep=',')\n",
    "train_wp3 = pd.read_csv('Data/Preprocessing/WP3_train_preprocessed.csv', sep=',')\n",
    "train_wp4 = pd.read_csv('Data/Preprocessing/WP4_train_preprocessed.csv', sep=',')\n",
    "train_wp5 = pd.read_csv('Data/Preprocessing/WP5_train_preprocessed.csv', sep=',')\n",
    "train_wp6 = pd.read_csv('Data/Preprocessing/WP6_train_preprocessed.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_wp1 = pd.read_csv('Data/Preprocessing/WP1_test_preprocessed.csv', sep=',')\n",
    "test_wp2 = pd.read_csv('Data/Preprocessing/WP2_test_preprocessed.csv', sep=',')\n",
    "test_wp3 = pd.read_csv('Data/Preprocessing/WP3_test_preprocessed.csv', sep=',')\n",
    "test_wp4 = pd.read_csv('Data/Preprocessing/WP4_test_preprocessed.csv', sep=',')\n",
    "test_wp5 = pd.read_csv('Data/Preprocessing/WP5_test_preprocessed.csv', sep=',')\n",
    "test_wp6 = pd.read_csv('Data/Preprocessing/WP6_test_preprocessed.csv', sep=',')\n",
    "test_dates = pd.read_csv('Data/Initial/test.csv', sep=',').date.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['date','wd','forecast_time', 'forecast', \"forecast_dist\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>ws</th>\n",
       "      <th>wd</th>\n",
       "      <th>forecast</th>\n",
       "      <th>forecast_time</th>\n",
       "      <th>forecast_dist</th>\n",
       "      <th>cos_hour</th>\n",
       "      <th>sin_hour</th>\n",
       "      <th>...</th>\n",
       "      <th>v_T_24_max</th>\n",
       "      <th>v_T_36_max</th>\n",
       "      <th>v_T_2_min</th>\n",
       "      <th>v_T_3_min</th>\n",
       "      <th>v_T_4_min</th>\n",
       "      <th>v_T_5_min</th>\n",
       "      <th>v_T_6_min</th>\n",
       "      <th>v_T_12_min</th>\n",
       "      <th>v_T_24_min</th>\n",
       "      <th>v_T_36_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-12-30 13:00:00</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>8.21</td>\n",
       "      <td>2.867054</td>\n",
       "      <td>358.14</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>2010-12-29 00:00:00</td>\n",
       "      <td>36.0</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>...</td>\n",
       "      <td>8.40</td>\n",
       "      <td>8.40</td>\n",
       "      <td>8.17</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.61</td>\n",
       "      <td>7.47</td>\n",
       "      <td>7.47</td>\n",
       "      <td>7.47</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-12-30 14:00:00</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>8.14</td>\n",
       "      <td>2.853069</td>\n",
       "      <td>357.96</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>2010-12-29 00:00:00</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.40</td>\n",
       "      <td>8.40</td>\n",
       "      <td>8.14</td>\n",
       "      <td>8.14</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.61</td>\n",
       "      <td>7.47</td>\n",
       "      <td>7.47</td>\n",
       "      <td>4.55</td>\n",
       "      <td>2.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-12-30 15:00:00</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>8.12</td>\n",
       "      <td>2.851315</td>\n",
       "      <td>358.11</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>2010-12-29 00:00:00</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>...</td>\n",
       "      <td>8.40</td>\n",
       "      <td>8.40</td>\n",
       "      <td>8.12</td>\n",
       "      <td>8.12</td>\n",
       "      <td>8.12</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.61</td>\n",
       "      <td>7.47</td>\n",
       "      <td>5.35</td>\n",
       "      <td>2.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-12-30 16:00:00</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>8.28</td>\n",
       "      <td>2.879236</td>\n",
       "      <td>358.59</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>2010-12-29 00:00:00</td>\n",
       "      <td>39.0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>...</td>\n",
       "      <td>8.40</td>\n",
       "      <td>8.40</td>\n",
       "      <td>8.12</td>\n",
       "      <td>8.12</td>\n",
       "      <td>8.12</td>\n",
       "      <td>8.12</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.47</td>\n",
       "      <td>6.12</td>\n",
       "      <td>2.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-12-30 17:00:00</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>8.52</td>\n",
       "      <td>2.918904</td>\n",
       "      <td>359.17</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>2010-12-29 00:00:00</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>...</td>\n",
       "      <td>8.52</td>\n",
       "      <td>8.52</td>\n",
       "      <td>8.28</td>\n",
       "      <td>8.12</td>\n",
       "      <td>8.12</td>\n",
       "      <td>8.12</td>\n",
       "      <td>8.12</td>\n",
       "      <td>7.47</td>\n",
       "      <td>6.63</td>\n",
       "      <td>2.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52003</th>\n",
       "      <td>2012-06-24 20:00:00</td>\n",
       "      <td>2.69</td>\n",
       "      <td>2.66</td>\n",
       "      <td>1.946792</td>\n",
       "      <td>45.36</td>\n",
       "      <td>2177.0</td>\n",
       "      <td>2012-06-23 00:00:00</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>...</td>\n",
       "      <td>5.49</td>\n",
       "      <td>5.49</td>\n",
       "      <td>2.66</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.63</td>\n",
       "      <td>-1.54</td>\n",
       "      <td>-1.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52004</th>\n",
       "      <td>2012-06-24 21:00:00</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1.77</td>\n",
       "      <td>1.621727</td>\n",
       "      <td>47.65</td>\n",
       "      <td>2177.0</td>\n",
       "      <td>2012-06-23 00:00:00</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>...</td>\n",
       "      <td>5.49</td>\n",
       "      <td>5.49</td>\n",
       "      <td>1.77</td>\n",
       "      <td>1.77</td>\n",
       "      <td>1.77</td>\n",
       "      <td>1.77</td>\n",
       "      <td>1.77</td>\n",
       "      <td>1.77</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>-1.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52005</th>\n",
       "      <td>2012-06-24 22:00:00</td>\n",
       "      <td>1.35</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>1.178983</td>\n",
       "      <td>103.63</td>\n",
       "      <td>2177.0</td>\n",
       "      <td>2012-06-23 00:00:00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.49</td>\n",
       "      <td>5.49</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-1.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52006</th>\n",
       "      <td>2012-06-24 23:00:00</td>\n",
       "      <td>1.02</td>\n",
       "      <td>-2.87</td>\n",
       "      <td>1.746425</td>\n",
       "      <td>160.40</td>\n",
       "      <td>2177.0</td>\n",
       "      <td>2012-06-23 00:00:00</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>...</td>\n",
       "      <td>5.49</td>\n",
       "      <td>5.49</td>\n",
       "      <td>-2.87</td>\n",
       "      <td>-2.87</td>\n",
       "      <td>-2.87</td>\n",
       "      <td>-2.87</td>\n",
       "      <td>-2.87</td>\n",
       "      <td>-2.87</td>\n",
       "      <td>-2.87</td>\n",
       "      <td>-2.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52007</th>\n",
       "      <td>2012-06-25 00:00:00</td>\n",
       "      <td>1.06</td>\n",
       "      <td>-4.80</td>\n",
       "      <td>2.215852</td>\n",
       "      <td>167.56</td>\n",
       "      <td>2177.0</td>\n",
       "      <td>2012-06-23 00:00:00</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.49</td>\n",
       "      <td>5.49</td>\n",
       "      <td>-4.80</td>\n",
       "      <td>-4.80</td>\n",
       "      <td>-4.80</td>\n",
       "      <td>-4.80</td>\n",
       "      <td>-4.80</td>\n",
       "      <td>-4.80</td>\n",
       "      <td>-4.80</td>\n",
       "      <td>-4.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52008 rows × 293 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date     u     v        ws      wd  forecast  \\\n",
       "0      2010-12-30 13:00:00 -0.27  8.21  2.867054  358.14    1093.0   \n",
       "1      2010-12-30 14:00:00 -0.29  8.14  2.853069  357.96    1093.0   \n",
       "2      2010-12-30 15:00:00 -0.27  8.12  2.851315  358.11    1093.0   \n",
       "3      2010-12-30 16:00:00 -0.20  8.28  2.879236  358.59    1093.0   \n",
       "4      2010-12-30 17:00:00 -0.12  8.52  2.918904  359.17    1093.0   \n",
       "...                    ...   ...   ...       ...     ...       ...   \n",
       "52003  2012-06-24 20:00:00  2.69  2.66  1.946792   45.36    2177.0   \n",
       "52004  2012-06-24 21:00:00  1.94  1.77  1.621727   47.65    2177.0   \n",
       "52005  2012-06-24 22:00:00  1.35 -0.33  1.178983  103.63    2177.0   \n",
       "52006  2012-06-24 23:00:00  1.02 -2.87  1.746425  160.40    2177.0   \n",
       "52007  2012-06-25 00:00:00  1.06 -4.80  2.215852  167.56    2177.0   \n",
       "\n",
       "             forecast_time  forecast_dist  cos_hour  sin_hour  ...  \\\n",
       "0      2010-12-29 00:00:00           36.0 -0.965926 -0.258819  ...   \n",
       "1      2010-12-29 00:00:00           37.0 -0.866025 -0.500000  ...   \n",
       "2      2010-12-29 00:00:00           38.0 -0.707107 -0.707107  ...   \n",
       "3      2010-12-29 00:00:00           39.0 -0.500000 -0.866025  ...   \n",
       "4      2010-12-29 00:00:00           40.0 -0.258819 -0.965926  ...   \n",
       "...                    ...            ...       ...       ...  ...   \n",
       "52003  2012-06-23 00:00:00           43.0  0.500000 -0.866025  ...   \n",
       "52004  2012-06-23 00:00:00           44.0  0.707107 -0.707107  ...   \n",
       "52005  2012-06-23 00:00:00           45.0  0.866025 -0.500000  ...   \n",
       "52006  2012-06-23 00:00:00           46.0  0.965926 -0.258819  ...   \n",
       "52007  2012-06-23 00:00:00           47.0  1.000000  0.000000  ...   \n",
       "\n",
       "       v_T_24_max  v_T_36_max  v_T_2_min  v_T_3_min  v_T_4_min  v_T_5_min  \\\n",
       "0            8.40        8.40       8.17       7.92       7.61       7.47   \n",
       "1            8.40        8.40       8.14       8.14       7.92       7.61   \n",
       "2            8.40        8.40       8.12       8.12       8.12       7.92   \n",
       "3            8.40        8.40       8.12       8.12       8.12       8.12   \n",
       "4            8.52        8.52       8.28       8.12       8.12       8.12   \n",
       "...           ...         ...        ...        ...        ...        ...   \n",
       "52003        5.49        5.49       2.66       2.63       2.63       2.63   \n",
       "52004        5.49        5.49       1.77       1.77       1.77       1.77   \n",
       "52005        5.49        5.49      -0.33      -0.33      -0.33      -0.33   \n",
       "52006        5.49        5.49      -2.87      -2.87      -2.87      -2.87   \n",
       "52007        5.49        5.49      -4.80      -4.80      -4.80      -4.80   \n",
       "\n",
       "       v_T_6_min  v_T_12_min  v_T_24_min  v_T_36_min  \n",
       "0           7.47        7.47        3.91        2.03  \n",
       "1           7.47        7.47        4.55        2.03  \n",
       "2           7.61        7.47        5.35        2.03  \n",
       "3           7.92        7.47        6.12        2.03  \n",
       "4           8.12        7.47        6.63        2.03  \n",
       "...          ...         ...         ...         ...  \n",
       "52003       2.63        2.63       -1.54       -1.72  \n",
       "52004       1.77        1.77       -1.10       -1.72  \n",
       "52005      -0.33       -0.33       -0.47       -1.72  \n",
       "52006      -2.87       -2.87       -2.87       -2.87  \n",
       "52007      -4.80       -4.80       -4.80       -4.80  \n",
       "\n",
       "[52008 rows x 293 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_wp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>ws</th>\n",
       "      <th>wd</th>\n",
       "      <th>forecast</th>\n",
       "      <th>forecast_time</th>\n",
       "      <th>forecast_dist</th>\n",
       "      <th>cos_hour</th>\n",
       "      <th>sin_hour</th>\n",
       "      <th>...</th>\n",
       "      <th>v_T_24_max</th>\n",
       "      <th>v_T_36_max</th>\n",
       "      <th>v_T_2_min</th>\n",
       "      <th>v_T_3_min</th>\n",
       "      <th>v_T_4_min</th>\n",
       "      <th>v_T_5_min</th>\n",
       "      <th>v_T_6_min</th>\n",
       "      <th>v_T_12_min</th>\n",
       "      <th>v_T_24_min</th>\n",
       "      <th>v_T_36_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-12-30 13:00:00</td>\n",
       "      <td>2.17</td>\n",
       "      <td>4.08</td>\n",
       "      <td>2.149419</td>\n",
       "      <td>27.97</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>2010-12-29 00:00:00</td>\n",
       "      <td>36.0</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>...</td>\n",
       "      <td>4.08</td>\n",
       "      <td>4.08</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.13</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.30</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>-0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-12-30 14:00:00</td>\n",
       "      <td>2.36</td>\n",
       "      <td>4.79</td>\n",
       "      <td>2.310844</td>\n",
       "      <td>26.24</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>2010-12-29 00:00:00</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.79</td>\n",
       "      <td>4.79</td>\n",
       "      <td>4.08</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.13</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.61</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>-0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-12-30 15:00:00</td>\n",
       "      <td>2.39</td>\n",
       "      <td>5.24</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>24.52</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>2010-12-29 00:00:00</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>...</td>\n",
       "      <td>5.24</td>\n",
       "      <td>5.24</td>\n",
       "      <td>4.79</td>\n",
       "      <td>4.08</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.13</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.09</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-12-30 16:00:00</td>\n",
       "      <td>2.08</td>\n",
       "      <td>5.18</td>\n",
       "      <td>2.362202</td>\n",
       "      <td>21.92</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>2010-12-29 00:00:00</td>\n",
       "      <td>39.0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>...</td>\n",
       "      <td>5.24</td>\n",
       "      <td>5.24</td>\n",
       "      <td>5.18</td>\n",
       "      <td>4.79</td>\n",
       "      <td>4.08</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.13</td>\n",
       "      <td>2.61</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-12-30 17:00:00</td>\n",
       "      <td>1.58</td>\n",
       "      <td>4.73</td>\n",
       "      <td>2.233831</td>\n",
       "      <td>18.44</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>2010-12-29 00:00:00</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>...</td>\n",
       "      <td>5.24</td>\n",
       "      <td>5.24</td>\n",
       "      <td>4.73</td>\n",
       "      <td>4.73</td>\n",
       "      <td>4.73</td>\n",
       "      <td>4.08</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.58</td>\n",
       "      <td>-0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52003</th>\n",
       "      <td>2012-06-24 20:00:00</td>\n",
       "      <td>0.69</td>\n",
       "      <td>2.33</td>\n",
       "      <td>1.558846</td>\n",
       "      <td>16.54</td>\n",
       "      <td>2177.0</td>\n",
       "      <td>2012-06-23 00:00:00</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.47</td>\n",
       "      <td>-2.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52004</th>\n",
       "      <td>2012-06-24 21:00:00</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.49</td>\n",
       "      <td>1.244990</td>\n",
       "      <td>16.35</td>\n",
       "      <td>2177.0</td>\n",
       "      <td>2012-06-23 00:00:00</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.49</td>\n",
       "      <td>1.49</td>\n",
       "      <td>1.49</td>\n",
       "      <td>1.49</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.47</td>\n",
       "      <td>-2.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52005</th>\n",
       "      <td>2012-06-24 22:00:00</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>21.36</td>\n",
       "      <td>2177.0</td>\n",
       "      <td>2012-06-23 00:00:00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.47</td>\n",
       "      <td>-2.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52006</th>\n",
       "      <td>2012-06-24 23:00:00</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.157584</td>\n",
       "      <td>24.53</td>\n",
       "      <td>2177.0</td>\n",
       "      <td>2012-06-23 00:00:00</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.47</td>\n",
       "      <td>-2.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52007</th>\n",
       "      <td>2012-06-25 00:00:00</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.66</td>\n",
       "      <td>1.326650</td>\n",
       "      <td>19.28</td>\n",
       "      <td>2177.0</td>\n",
       "      <td>2012-06-23 00:00:00</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.47</td>\n",
       "      <td>-2.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52008 rows × 293 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date     u     v        ws     wd  forecast  \\\n",
       "0      2010-12-30 13:00:00  2.17  4.08  2.149419  27.97    1093.0   \n",
       "1      2010-12-30 14:00:00  2.36  4.79  2.310844  26.24    1093.0   \n",
       "2      2010-12-30 15:00:00  2.39  5.24  2.400000  24.52    1093.0   \n",
       "3      2010-12-30 16:00:00  2.08  5.18  2.362202  21.92    1093.0   \n",
       "4      2010-12-30 17:00:00  1.58  4.73  2.233831  18.44    1093.0   \n",
       "...                    ...   ...   ...       ...    ...       ...   \n",
       "52003  2012-06-24 20:00:00  0.69  2.33  1.558846  16.54    2177.0   \n",
       "52004  2012-06-24 21:00:00  0.44  1.49  1.244990  16.35    2177.0   \n",
       "52005  2012-06-24 22:00:00  0.44  1.13  1.100000  21.36    2177.0   \n",
       "52006  2012-06-24 23:00:00  0.56  1.22  1.157584  24.53    2177.0   \n",
       "52007  2012-06-25 00:00:00  0.58  1.66  1.326650  19.28    2177.0   \n",
       "\n",
       "             forecast_time  forecast_dist  cos_hour  sin_hour  ...  \\\n",
       "0      2010-12-29 00:00:00           36.0 -0.965926 -0.258819  ...   \n",
       "1      2010-12-29 00:00:00           37.0 -0.866025 -0.500000  ...   \n",
       "2      2010-12-29 00:00:00           38.0 -0.707107 -0.707107  ...   \n",
       "3      2010-12-29 00:00:00           39.0 -0.500000 -0.866025  ...   \n",
       "4      2010-12-29 00:00:00           40.0 -0.258819 -0.965926  ...   \n",
       "...                    ...            ...       ...       ...  ...   \n",
       "52003  2012-06-23 00:00:00           43.0  0.500000 -0.866025  ...   \n",
       "52004  2012-06-23 00:00:00           44.0  0.707107 -0.707107  ...   \n",
       "52005  2012-06-23 00:00:00           45.0  0.866025 -0.500000  ...   \n",
       "52006  2012-06-23 00:00:00           46.0  0.965926 -0.258819  ...   \n",
       "52007  2012-06-23 00:00:00           47.0  1.000000  0.000000  ...   \n",
       "\n",
       "       v_T_24_max  v_T_36_max  v_T_2_min  v_T_3_min  v_T_4_min  v_T_5_min  \\\n",
       "0            4.08        4.08       3.44       3.13       3.10       3.10   \n",
       "1            4.79        4.79       4.08       3.44       3.13       3.10   \n",
       "2            5.24        5.24       4.79       4.08       3.44       3.13   \n",
       "3            5.24        5.24       5.18       4.79       4.08       3.44   \n",
       "4            5.24        5.24       4.73       4.73       4.73       4.08   \n",
       "...           ...         ...        ...        ...        ...        ...   \n",
       "52003        4.00        4.00       2.33       2.33       2.33       2.33   \n",
       "52004        4.00        4.00       1.49       1.49       1.49       1.49   \n",
       "52005        4.00        4.00       1.13       1.13       1.13       1.13   \n",
       "52006        4.00        4.00       1.13       1.13       1.13       1.13   \n",
       "52007        4.00        4.00       1.22       1.13       1.13       1.13   \n",
       "\n",
       "       v_T_6_min  v_T_12_min  v_T_24_min  v_T_36_min  \n",
       "0           3.10        1.30       -0.62       -0.88  \n",
       "1           3.10        1.61       -0.53       -0.88  \n",
       "2           3.10        2.09       -0.23       -0.88  \n",
       "3           3.13        2.61        0.19       -0.84  \n",
       "4           3.44        3.03        0.58       -0.77  \n",
       "...          ...         ...         ...         ...  \n",
       "52003       2.33        0.95        0.47       -2.76  \n",
       "52004       1.49        0.95        0.47       -2.76  \n",
       "52005       1.13        0.95        0.47       -2.76  \n",
       "52006       1.13        1.02        0.47       -2.76  \n",
       "52007       1.13        1.13        0.47       -2.76  \n",
       "\n",
       "[52008 rows x 293 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_wp2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def xgboost_cross_validation(X, y, params):\n",
    "#     if params == None:\n",
    "#         model = XGBRegressor()\n",
    "#     else:\n",
    "#         model = XGBRegressor(**params)\n",
    "\n",
    "#     print('-----------XGBOOST CROSS VALIDATION BEGINNING-----------')\n",
    "#     split = 10\n",
    "#     kf = KFold(n_splits=split, shuffle=True)       \n",
    "#     xgboost_rmse_scores = []\n",
    "#     xgboost_mae_scores = []\n",
    "#     i = 1\n",
    "#     for (train_index, test_index) in kf.split(pd.DataFrame(X), pd.DataFrame(y)):\n",
    "#         X_train, X_test = pd.DataFrame(X).iloc[train_index], pd.DataFrame(X).iloc[test_index]\n",
    "#         Y_train, Y_test = pd.DataFrame(y).iloc[train_index],pd.DataFrame(y).iloc[test_index]\n",
    "\n",
    "#         model.fit(X_train, Y_train, eval_set=[(X_test, Y_test)], verbose=100)\n",
    "\n",
    "#         prediction = model.predict(X_test)\n",
    "#         xgboost_rmse_scores.append(mean_squared_error(Y_test, prediction,squared=False))\n",
    "#         xgboost_mae_scores.append(mean_absolute_error(Y_test, prediction))\n",
    "        \n",
    "#         print(show_evaluation(prediction, Y_test))\n",
    "#         print(f'-------------------FOLD {i}-----------------')\n",
    "#         i+=1\n",
    "\n",
    "#     print('---------------CROSS VALIDATION COMPLETE-------------')\n",
    "#     print('--------------------------RMSE-----------------------')\n",
    "#     display_scores(xgboost_rmse_scores)\n",
    "#     print('--------------------------MAE------------------------')\n",
    "#     display_scores(xgboost_mae_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_cross_validation(X, y, params):\n",
    "    if params == None:\n",
    "        model = Pipeline([('scaler', MaxAbsScaler()),('xgbr', XGBRegressor())])\n",
    "    else:\n",
    "        model = Pipeline([('scaler', MaxAbsScaler()),('xgbr', XGBRegressor(**params))])\n",
    "\n",
    "    print('-----------XGBOOST CROSS VALIDATION BEGINNING-----------')\n",
    "    split = 10\n",
    "    kf = KFold(n_splits=split, shuffle=True)       \n",
    "    xgboost_rmse_scores = []\n",
    "    xgboost_mae_scores = []\n",
    "    i = 1\n",
    "    for (train_index, test_index) in kf.split(pd.DataFrame(X), pd.DataFrame(y)):\n",
    "        X_train, X_test = pd.DataFrame(X).iloc[train_index], pd.DataFrame(X).iloc[test_index]\n",
    "        Y_train, Y_test = pd.DataFrame(y).iloc[train_index],pd.DataFrame(y).iloc[test_index]\n",
    "\n",
    "        model.fit(X_train, Y_train)\n",
    "\n",
    "        prediction = model.predict(X_test)\n",
    "        xgboost_rmse_scores.append(mean_squared_error(Y_test, prediction,squared=False))\n",
    "        xgboost_mae_scores.append(mean_absolute_error(Y_test, prediction))\n",
    "        \n",
    "        print(show_evaluation(prediction, Y_test))\n",
    "        print(f'-------------------FOLD {i}-----------------')\n",
    "        i+=1\n",
    "\n",
    "    print('---------------CROSS VALIDATION COMPLETE-------------')\n",
    "    print('--------------------------RMSE-----------------------')\n",
    "    display_scores(xgboost_rmse_scores)\n",
    "    print('--------------------------MAE------------------------')\n",
    "    display_scores(xgboost_mae_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def hyperparametrization(trial, train_x, test_x, train_y, test_y):\n",
    "#     param = {\n",
    "#         'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
    "#         'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
    "#         'colsample_bytree': trial.suggest_loguniform('colsample_bytree', 1e-8, 1),\n",
    "#         'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n",
    "#         'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 100, 700),\n",
    "#         'max_depth': trial.suggest_int(\"max_depth\", 20, 70),\n",
    "#         'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
    "#         'eta' : trial.suggest_loguniform(\"eta\", 1e-8, 1.0),\n",
    "#         'gamma' : trial.suggest_loguniform(\"gamma\", 1e-8, 1.0),\n",
    "#         'grow_policy' : trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
    "#     }\n",
    "#     model = XGBRegressor(**param)  \n",
    "    \n",
    "#     model.fit(train_x,train_y,eval_set=[(test_x,test_y)],early_stopping_rounds=100,verbose=False)\n",
    "    \n",
    "#     preds = model.predict(test_x)\n",
    "    \n",
    "#     rmse =  mean_squared_error(test_y, preds,squared=False)\n",
    "    \n",
    "#     return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hyperparametrization(trial, train_x, test_x, train_y, test_y):\n",
    "    param = {\n",
    "        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
    "        'colsample_bytree': trial.suggest_loguniform('colsample_bytree', 1e-8, 1),\n",
    "        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 700),\n",
    "        'max_depth': trial.suggest_int(\"max_depth\", 20, 70),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
    "        'eta' : trial.suggest_loguniform(\"eta\", 1e-8, 1.0),\n",
    "        'gamma' : trial.suggest_loguniform(\"gamma\", 1e-8, 1.0),\n",
    "        'grow_policy' : trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
    "    }\n",
    "    model = Pipeline([('scaler', MaxAbsScaler()),('xgbr', XGBRegressor(**param))]) \n",
    "    \n",
    "    model.fit(train_x,train_y)\n",
    "    \n",
    "    preds = model.predict(test_x)\n",
    "    \n",
    "    rmse =  mean_squared_error(test_y, preds,squared=False)\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WP1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| |  | Mean | Std | Sum up |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| No params | RMSE | 0.08791418461185974 | 0.001582447940959254 |  |\n",
    "| No params - MaxAbs | RMSE | 0.08777836846276121 | 0.0014715383851711332 |  |\n",
    "| After tuning 50trials| RMSE | 0.06871560882190697 | 0.0009799918898982718 |  |\n",
    "| After tuning 50trials - MaxAbs | RMSE | 0.06436201945957092 | 0.0016136864674464234 |  |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| No params | MAE | 0.0614505433779813 | 0.0010902461358058533 |  |\n",
    "| No params - MaxAbs | MAE | 0.06135361126361555 | 0.0009797777856978493 |  |\n",
    "| After tuning 50trials| MAE | 0.0447212685268329 | 0.0006115489443412801 |  |\n",
    "| After tuning 50trials - MaxAbs | MAE | 0.04177557094032202 | 0.0008888330284581335 |  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wp1_X = train_wp1[[c for c in train_wp1 if c not in [\"wp\"]] + [\"wp\"]].drop(to_drop, axis = 1)\n",
    "X1 = wp1_X.drop('wp', axis=1)\n",
    "y1 = wp1_X['wp']\n",
    "\n",
    "def objective_wp1(trial,data=X1,target=y1):\n",
    "    train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.15,random_state=42)\n",
    "    return hyperparametrization(trial, train_x, test_x, train_y, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# xgboost_cross_validation(X1, y1, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# try_these_first = [{\n",
    "#     'lambda': 2.1359622347936646,\n",
    "#     'alpha': 0.016202766042783825,\n",
    "#     'colsample_bytree': 0.8075360516891219,\n",
    "#     'subsample': 0.8,\n",
    "#     'learning_rate': 0.06792370224097045,\n",
    "#     'n_estimators': 320,\n",
    "#     'max_depth': 58,\n",
    "#     'min_child_weight': 102,\n",
    "#     'eta': 6.934521001624072e-05,\n",
    "#     'gamma': 4.369012735807193e-06,\n",
    "#     'grow_policy': 'lossguide'\n",
    "# },  {\n",
    "#     'lambda': 0.3643806022565838,\n",
    "#     'alpha': 0.003650309466012506,\n",
    "#     'colsample_bytree': 0.9640425007241273,\n",
    "#     'subsample': 0.8,\n",
    "#     'learning_rate': 0.052762727588106954,\n",
    "#     'n_estimators': 700,\n",
    "#     'max_depth': 54,\n",
    "#     'min_child_weight': 96,\n",
    "#     'eta': 3.119364108002744e-05,\n",
    "#     'gamma': 5.177778739056542e-05,\n",
    "#     'grow_policy': 'lossguide'\n",
    "# }]\n",
    "\n",
    "# study = optuna.create_study(direction='minimize')\n",
    "# study.enqueue_trial(try_these_first[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # study = optuna.create_study(direction='minimize')\n",
    "# study.optimize(objective_wp1, n_trials=50)\n",
    "# # write_results('Data/Hyperparametrization/xgboost_50trials.xlsx', 'wp1', study.trials_dataframe())\n",
    "# best_trial = study.best_trial.params\n",
    "# best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warm start MaxAbs\n",
    "params_1 = {\n",
    "    'lambda': 0.3643806022565838,\n",
    "    'alpha': 0.003650309466012506,\n",
    "    'colsample_bytree': 0.9640425007241273,\n",
    "    'subsample': 0.8,\n",
    "    'learning_rate': 0.052762727588106954,\n",
    "    'n_estimators': 700,\n",
    "    'max_depth': 54,\n",
    "    'min_child_weight': 96,\n",
    "    'eta': 3.119364108002744e-05,\n",
    "    'gamma': 5.177778739056542e-05,\n",
    "    'grow_policy': 'lossguide'\n",
    "}\n",
    "\n",
    "# 50 trials no scaler\n",
    "# params_1 = {\n",
    "#     'lambda': 2.1359622347936646,\n",
    "#     'alpha': 0.016202766042783825,\n",
    "#     'colsample_bytree': 0.8075360516891219,\n",
    "#     'subsample': 0.8,\n",
    "#     'learning_rate': 0.06792370224097045,\n",
    "#     'n_estimators': 320,\n",
    "#     'max_depth': 58,\n",
    "#     'min_child_weight': 102,\n",
    "#     'eta': 6.934521001624072e-05,\n",
    "#     'gamma': 4.369012735807193e-06,\n",
    "#     'grow_policy': 'lossguide'\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# xgboost_cross_validation(X1, y1, params_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WP2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| |  | Mean | Std | Sum up |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| No params | RMSE | 0.09275649653219382 | 0.0018096321280782113 |  |\n",
    "| No params - MaxAbs | RMSE | 0.09230889203333872 | 0.0020804503145906636 |  |\n",
    "| After tuning 100trials| RMSE | 0.07182012947223423 | 0.0012496316182635523 |  |\n",
    "| After tuning 50trials - MaxAbs | RMSE | 0.06859684788065064 | 0.0016932252507600254 |  |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| No params | MAE | 0.0639385458606043 | 0.0009679991365400539 |  |\n",
    "| No params - MaxAbs | MAE | 0.06371111009968947 | 0.001194440893727917 |  |\n",
    "| After tuning 100trials| MAE | 0.04649572151134333 | 0.0006489429134030307 |  |\n",
    "| After tuning 50trials - MaxAbs | MAE | 0.044900768162719054 | 0.0006831432438047666 |  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "wp2_X = train_wp2[[c for c in train_wp2 if c not in [\"wp\"]] + [\"wp\"]].drop(to_drop, axis = 1)\n",
    "X2 = wp2_X.drop('wp', axis=1)\n",
    "y2 = wp2_X['wp']\n",
    "\n",
    "def objective_wp2(trial,data = X2,target = y2):\n",
    "    train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.15,random_state=42)\n",
    "    return hyperparametrization(trial, train_x, test_x, train_y, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# xgboost_cross_validation(X2, y2, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# try_these_first = [{\n",
    "#     'lambda': 2.1359622347936646,\n",
    "#     'alpha': 0.016202766042783825,\n",
    "#     'colsample_bytree': 0.8075360516891219,\n",
    "#     'subsample': 0.8,\n",
    "#     'learning_rate': 0.06792370224097045,\n",
    "#     'n_estimators': 320,\n",
    "#     'max_depth': 58,\n",
    "#     'min_child_weight': 102,\n",
    "#     'eta': 6.934521001624072e-05,\n",
    "#     'gamma': 4.369012735807193e-06,\n",
    "#     'grow_policy': 'lossguide'\n",
    "# }]\n",
    "\n",
    "# study = optuna.create_study(direction='minimize')\n",
    "# study.enqueue_trial(try_these_first[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # study = optuna.create_study(direction='minimize')\n",
    "# study.optimize(objective_wp2, n_trials=50)\n",
    "# # write_results('Data/Hyperparametrization/xgboost_50trials.xlsx', 'wp2', study.trials_dataframe())\n",
    "# best_trial = study.best_trial.params\n",
    "# best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50 tirals - warm start MaxAbs\n",
    "params_2 = {\n",
    "    'lambda': 0.005195058020286749,\n",
    "    'alpha': 0.15427340616771562,\n",
    "    'colsample_bytree': 0.4794118698886291,\n",
    "    'subsample': 0.7,\n",
    "    'learning_rate': 0.13969003989794868,\n",
    "    'n_estimators': 583,\n",
    "    'max_depth': 20,\n",
    "    'min_child_weight': 81,\n",
    "    'eta': 0.0006994052800675432,\n",
    "    'gamma': 4.0927842177131904e-08,\n",
    "    'grow_policy': 'depthwise'\n",
    "}\n",
    "\n",
    "# {\n",
    "#     'lambda': 4.982427302967441,\n",
    "#     'alpha': 0.023879453147379343,\n",
    "#     'colsample_bytree': 0.29850970311481473,\n",
    "#     'subsample': 0.7,\n",
    "#     'learning_rate': 0.07986759823219342,\n",
    "#     'n_estimators': 634,\n",
    "#     'max_depth': 52,\n",
    "#     'min_child_weight': 142,\n",
    "#     'eta': 0.9698508070965183,\n",
    "#     'gamma': 6.168834828494383e-06,\n",
    "#     'grow_policy': 'depthwise'\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# xgboost_cross_validation(X2, y2, params_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WP3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| |  | Mean | Std | Sum up |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| No params | RMSE | 0.08531695654385577 | 0.0009512381902157176 |  |\n",
    "| No params - MaxAbs | RMSE | 0.08509439114002723 | 0.0018013097694686512 |  |\n",
    "| After tuning 100trials| RMSE | 0.0573197789387906 | 0.0008490715337388156 |  |\n",
    "| After tuning 50trials - MaxAbs | RMSE | 0.057135478429648404 | 0.0010258941390154284 |  |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| No params | MAE | 0.06125227568636895 | 0.000538637024754324 |  |\n",
    "| No params - MaxAbs | MAE | 0.06109215580462539 | 0.0011200741022377755 |  |\n",
    "| After tuning 100trials| MAE | 0.04009718047732659 | 0.000599116601355594 |  |\n",
    "| After tuning 50trials - MaxAbs | MAE | 0.040053630091772346 | 0.0006140572130488917 |  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "wp3_X = train_wp3[[c for c in train_wp3 if c not in [\"wp\"]] + [\"wp\"]].drop(to_drop, axis = 1)\n",
    "X3 = wp3_X.drop('wp', axis = 1)\n",
    "y3 = wp3_X['wp']\n",
    "\n",
    "def objective_wp3(trial,data = X3,target = y3):\n",
    "    train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.15,random_state=42)\n",
    "    return hyperparametrization(trial, train_x, test_x, train_y, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# xgboost_cross_validation(X3, y3, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# try_these_first = [{\n",
    "#     'lambda': 0.018191871915246106,\n",
    "#     'alpha': 0.2397827070234125,\n",
    "#     'colsample_bytree': 0.4710946041352672,\n",
    "#     'subsample': 0.8,\n",
    "#     'learning_rate': 0.14812785561924302,\n",
    "#     'n_estimators': 688,\n",
    "#     'max_depth': 32,\n",
    "#     'min_child_weight': 218,\n",
    "#     'eta': 6.950960910550952e-08,\n",
    "#     'gamma': 2.0149702062428016e-07,\n",
    "#     'grow_policy': 'lossguide'\n",
    "# }]\n",
    "\n",
    "# study = optuna.create_study(direction='minimize')\n",
    "# study.enqueue_trial(try_these_first[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # study = optuna.create_study(direction='minimize')\n",
    "# study.optimize(objective_wp3, n_trials=50)\n",
    "# # write_results('Data/Hyperparametrization/xgboost_50trials.xlsx', 'wp3', study.trials_dataframe())\n",
    "# best_trial = study.best_trial.params\n",
    "# best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50 tirals - warm start MaxAbs\n",
    "params_3 = {\n",
    "    'lambda': 0.018191871915246106,\n",
    "    'alpha': 0.2397827070234125,\n",
    "    'colsample_bytree': 0.4710946041352672,\n",
    "    'subsample': 0.8,\n",
    "    'learning_rate': 0.14812785561924302,\n",
    "    'n_estimators': 688,\n",
    "    'max_depth': 32,\n",
    "    'min_child_weight': 218,\n",
    "    'eta': 6.950960910550952e-08,\n",
    "    'gamma': 2.0149702062428016e-07,\n",
    "    'grow_policy': 'lossguide'\n",
    "}\n",
    "\n",
    "# {\n",
    "#     'lambda': 0.018191871915246106,\n",
    "#     'alpha': 0.2397827070234125,\n",
    "#     'colsample_bytree': 0.4710946041352672,\n",
    "#     'subsample': 0.8,\n",
    "#     'learning_rate': 0.14812785561924302,\n",
    "#     'n_estimators': 688,\n",
    "#     'max_depth': 32,\n",
    "#     'min_child_weight': 218,\n",
    "#     'eta': 6.950960910550952e-08,\n",
    "#     'gamma': 2.0149702062428016e-07,\n",
    "#     'grow_policy': 'lossguide'\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# xgboost_cross_validation(X3, y3, params_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WP4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| |  | Mean | Std | Sum up |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| No params | RMSE | 0.08705646834205574 | 0.0013432615911574354 |  |\n",
    "| No params - MaxAbs | RMSE | 0.0870757500361273 | 0.0014362323840110152 |  |\n",
    "| After tuning 100trials| RMSE | 0.06505388151301929 | 0.0009022910606251192 |  |\n",
    "| After tuning 50trials - MaxAbs | RMSE | 0.0626312118373484 | 0.0010312894520400255 |  |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| No params | MAE | 0.06217383365682638 | 0.000883527934746644 |  |\n",
    "| No params - MaxAbs | MAE | 0.062254149447791104 | 0.062254149447791104 |  |\n",
    "| After tuning 100trials| MAE | 0.043762279489834674 | 0.0004905220832103441 |  |\n",
    "| After tuning 50trials - MaxAbs | MAE | 0.041378801055099515 | 0.0007406645752025426 |  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "wp4_X = train_wp4[[c for c in train_wp4 if c not in [\"wp\"]] + [\"wp\"]].drop(to_drop, axis = 1)\n",
    "X4 = wp4_X.drop('wp', axis = 1)\n",
    "y4 = wp4_X['wp']\n",
    "\n",
    "def objective_wp4(trial,data = X4,target = y4):\n",
    "    train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.15,random_state=42)\n",
    "    return hyperparametrization(trial, train_x, test_x, train_y, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# xgboost_cross_validation(X4, y4, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# try_these_first = [{\n",
    "#     'lambda': 0.001340947773207149,\n",
    "#     'alpha': 0.002479638085657274,\n",
    "#     'colsample_bytree': 0.3030181981060389,\n",
    "#     'subsample': 0.7,\n",
    "#     'learning_rate': 0.07696248319007938,\n",
    "#     'n_estimators': 367,\n",
    "#     'max_depth': 31,\n",
    "#     'min_child_weight': 72,\n",
    "#     'eta': 3.704957186572025e-08,\n",
    "#     'gamma': 8.44315434172209e-05,\n",
    "#     'grow_policy': 'depthwise'\n",
    "# }, {\n",
    "#     'lambda': 0.13763482520556616,\n",
    "#     'alpha': 0.0010077676339636944,\n",
    "#     'colsample_bytree': 0.954734556572597,\n",
    "#     'subsample': 0.8,\n",
    "#     'learning_rate': 0.05499114408834853,\n",
    "#     'n_estimators': 546,\n",
    "#     'max_depth': 43,\n",
    "#     'min_child_weight': 94,\n",
    "#     'eta': 1.2784286267654713e-06,\n",
    "#     'gamma': 1.6935174502873177e-05,\n",
    "#     'grow_policy': 'depthwise'\n",
    "# }]\n",
    "\n",
    "# study = optuna.create_study(direction='minimize')\n",
    "# study.enqueue_trial(try_these_first[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # study = optuna.create_study(direction='minimize')\n",
    "# study.optimize(objective_wp4, n_trials=50)\n",
    "# # write_results('Data/Hyperparametrization/xgboost_50trials.xlsx', 'wp4', study.trials_dataframe())\n",
    "# best_trial = study.best_trial.params\n",
    "# best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50 tirals - warm start MaxAbs\n",
    "params_4 = {\n",
    "    'lambda': 0.13763482520556616,\n",
    "    'alpha': 0.0010077676339636944,\n",
    "    'colsample_bytree': 0.954734556572597,\n",
    "    'subsample': 0.8,\n",
    "    'learning_rate': 0.05499114408834853,\n",
    "    'n_estimators': 546,\n",
    "    'max_depth': 43,\n",
    "    'min_child_weight': 94,\n",
    "    'eta': 1.2784286267654713e-06,\n",
    "    'gamma': 1.6935174502873177e-05,\n",
    "    'grow_policy': 'depthwise'\n",
    "}\n",
    "\n",
    "# 50 trials\n",
    "# params_4 = {\n",
    "#     'lambda': 0.001340947773207149,\n",
    "#     'alpha': 0.002479638085657274,\n",
    "#     'colsample_bytree': 0.3030181981060389,\n",
    "#     'subsample': 0.7,\n",
    "#     'learning_rate': 0.07696248319007938,\n",
    "#     'n_estimators': 367,\n",
    "#     'max_depth': 31,\n",
    "#     'min_child_weight': 72,\n",
    "#     'eta': 3.704957186572025e-08,\n",
    "#     'gamma': 8.44315434172209e-05,\n",
    "#     'grow_policy': 'depthwise'\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# xgboost_cross_validation(X4, y4, params_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WP5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| |  | Mean | Std | Sum up |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| No params | RMSE | 0.09905505938942759 | 0.0010560057294061722 |  |\n",
    "| No params - MaxAbs | RMSE | 0.09902019521905119 | 0.0013460300390687509 |  |\n",
    "| After tuning 100trials| RMSE | 0.07467175992757297 | 0.0018566395951414925 |  |\n",
    "| After tuning 50trials - MaxAbs | RMSE | 0.07315316873758233 | 0.0021847037668090933 |  |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| No params | MAE | 0.0703001590429472 | 0.0006221166408279179 |  |\n",
    "| No params - MaxAbs | MAE | 0.07031017432456337 | 0.0008486582761726584 |  |\n",
    "| After tuning 100trials| MAE | 0.05087662307993675 | 0.0010894679027767663 |  |\n",
    "| After tuning 50trials - MaxAbs | MAE | 0.04890386336557044 | 0.0010155747369788642 |  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "wp5_X = train_wp5[[c for c in train_wp5 if c not in [\"wp\"]] + [\"wp\"]].drop(to_drop, axis = 1)\n",
    "X5 = wp5_X.drop('wp', axis = 1)\n",
    "y5 = wp5_X['wp']\n",
    "\n",
    "def objective_wp5(trial, data = X5,target = y5):\n",
    "    train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.15,random_state=42)\n",
    "    return hyperparametrization(trial, train_x, test_x, train_y, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# xgboost_cross_validation(X5, y5, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# try_these_first = [{\n",
    "#     'lambda': 4.537995153532639,\n",
    "#     'alpha': 0.15887083612902936,\n",
    "#     'colsample_bytree': 0.35129085402309673,\n",
    "#     'subsample': 0.8,\n",
    "#     'learning_rate': 0.20146110291550628,\n",
    "#     'n_estimators': 354,\n",
    "#     'max_depth': 27,\n",
    "#     'min_child_weight': 91,\n",
    "#     'eta': 0.1963402390178624,\n",
    "#     'gamma': 4.730295821405375e-07,\n",
    "#     'grow_policy': 'lossguide'\n",
    "# }]\n",
    "\n",
    "# study = optuna.create_study(direction='minimize')\n",
    "# study.enqueue_trial(try_these_first[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # study = optuna.create_study(direction='minimize')\n",
    "# study.optimize(objective_wp5, n_trials=50)\n",
    "# # write_results('Data/Hyperparametrization/xgboost_50trials.xlsx', 'wp5', study.trials_dataframe())\n",
    "# best_trial = study.best_trial.params\n",
    "# best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50 start warm - MaxAbs\n",
    "params_5 = {\n",
    "    'lambda': 4.7653031074423104,\n",
    "    'alpha': 0.004963619239675007,\n",
    "    'colsample_bytree': 0.8616303151950829,\n",
    "    'subsample': 0.8,\n",
    "    'learning_rate': 0.167247240657064,\n",
    "    'n_estimators': 509,\n",
    "    'max_depth': 31,\n",
    "    'min_child_weight': 73,\n",
    "    'eta': 0.1392993925005545,\n",
    "    'gamma': 1.4909263616645174e-07,\n",
    "    'grow_policy': 'depthwise'\n",
    "}\n",
    "\n",
    "# 50 trials\n",
    "# params_5 = {\n",
    "#     'lambda': 4.537995153532639,\n",
    "#     'alpha': 0.15887083612902936,\n",
    "#     'colsample_bytree': 0.35129085402309673,\n",
    "#     'subsample': 0.8,\n",
    "#     'learning_rate': 0.20146110291550628,\n",
    "#     'n_estimators': 354,\n",
    "#     'max_depth': 27,\n",
    "#     'min_child_weight': 91,\n",
    "#     'eta': 0.1963402390178624,\n",
    "#     'gamma': 4.730295821405375e-07,\n",
    "#     'grow_policy': 'lossguide'\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# xgboost_cross_validation(X5, y5, params_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WP6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| |  | Mean | Std | Sum up |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| No params | RMSE |  0.07704369819527615 | 0.0010801451601647142 |  |\n",
    "| No params - MaxAbs | RMSE | 0.07724267929514025 | 0.0015012274298760973 |  |\n",
    "| After tuning 100trials| RMSE | 0.052403202133489465 | 0.0010631888908178239 |  |\n",
    "| After tuning 50trials - warm start - MaxAbs | RMSE | 0.051604419990347344 | 0.0008376347497504802 |  |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| No params | MAE | 0.056804680824990995 | 0.000879205156712233 |  |\n",
    "| No params - MaxAbs | MAE | 0.0568038624920563 | 0.0007877324372786336 |  |\n",
    "| After tuning 100trials| MAE | 0.03630430575055383 | 0.0007604647331428116 |  |\n",
    "| After tuning 50trials - warm start - MaxAbs | MAE | 0.03479476729901705 | 0.0004812579905210939 |  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wp6_X = train_wp6[[c for c in train_wp6 if c not in [\"wp\"]] + [\"wp\"]].drop(to_drop, axis = 1)\n",
    "X6 = wp6_X.drop('wp', axis = 1)\n",
    "y6 = wp6_X['wp']\n",
    "\n",
    "def objective_wp6(trial,data = X6,target = y6):\n",
    "    train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.15,random_state=42)\n",
    "    return hyperparametrization(trial, train_x, test_x, train_y, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# xgboost_cross_validation(X6, y6, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# try_these_first = [{\n",
    "#     'lambda': 0.5705269295320163,\n",
    "#     'alpha': 0.06713843687958011,\n",
    "#     'colsample_bytree': 0.8718486759988152,\n",
    "#     'subsample': 0.8,\n",
    "#     'learning_rate': 0.07668854905667996,\n",
    "#     'n_estimators': 582,\n",
    "#     'max_depth': 49,\n",
    "#     'min_child_weight': 143,\n",
    "#     'eta': 9.055710235537663e-07,\n",
    "#     'gamma': 1.111486195598291e-06,\n",
    "#     'grow_policy': 'depthwise'\n",
    "# }]\n",
    "\n",
    "# study = optuna.create_study(direction='minimize')\n",
    "# study.enqueue_trial(try_these_first[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # study = optuna.create_study(direction='minimize')\n",
    "# study.optimize(objective_wp6, n_trials=50)\n",
    "# # write_results('Data/Hyperparametrization/xgboost_50trials.xlsx', 'wp6', study.trials_dataframe())\n",
    "# best_trial = study.best_trial.params\n",
    "# best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50 start warm - MaxAbs\n",
    "params_6 = {\n",
    "    'lambda': 6.198890709955999,\n",
    "    'alpha': 0.009212761583335095,\n",
    "    'colsample_bytree': 0.9364947872025757,\n",
    "    'subsample': 0.6,\n",
    "    'learning_rate': 0.0377294321765545,\n",
    "    'n_estimators': 458,\n",
    "    'max_depth': 50,\n",
    "    'min_child_weight': 28,\n",
    "    'eta': 1.0671149195024988e-08,\n",
    "    'gamma': 1.4697758952551594e-05,\n",
    "    'grow_policy': 'depthwise'\n",
    "}\n",
    "\n",
    "\n",
    "# A REFAIRE TOURNER\n",
    "# {\n",
    "#     'lambda': 0.5705269295320163,\n",
    "#     'alpha': 0.06713843687958011,\n",
    "#     'colsample_bytree': 0.8718486759988152,\n",
    "#     'subsample': 0.8,\n",
    "#     'learning_rate': 0.07668854905667996,\n",
    "#     'n_estimators': 582,\n",
    "#     'max_depth': 49,\n",
    "#     'min_child_weight': 143,\n",
    "#     'eta': 9.055710235537663e-07,\n",
    "#     'gamma': 1.111486195598291e-06,\n",
    "#     'grow_policy': 'depthwise'\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# xgboost_cross_validation(X6, y6, params_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['date','wd','forecast_time', 'forecast', \"forecast_dist\", 'wp']\n",
    "def make_prediction_dataset(test, to_drop=to_drop):\n",
    "    test_to_predict = test.dropna(subset=['ws','u','v'], how = 'any') # keeps only lines with u,v,ws,wd\n",
    "    test_to_predict = test_to_predict[test_to_predict['wp'].isna()] # keeps only lines with no wp\n",
    "    test_to_predict = test_to_predict.sort_values(by=['date', 'forecast_time'], ascending = [True, False]).drop_duplicates(subset='date')\n",
    "    test_to_predict = test_to_predict.drop(to_drop, axis = 1)\n",
    "    return test_to_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission_file(lst_X_trains, lst_y_trains, lst_tests, lst_models, dates):\n",
    "    i = 1\n",
    "    lst_prediction = []\n",
    "    lst_models_trained = []\n",
    "    for X, y, test, model in zip(lst_X_trains, lst_y_trains, lst_tests, lst_models):\n",
    "        print(f'--------------Model {i}--------------')\n",
    "        model.fit(X, y)\n",
    "        print(f'True:\\n\\tMin:{min(y)}\\n\\tMax:{max(y)}\\n\\tMean:{y.mean()}')\n",
    "        predictions = model.predict(test)\n",
    "        print(f'Prediction:\\n\\tMin:{min(predictions)}\\n\\tMax:{max(predictions)}\\n\\tMean:{np.mean(predictions)}')\n",
    "        predictions = [min(y) if i < 0 else i for i in predictions]\n",
    "        predictions = [max(y) if i > max(y) else i for i in predictions]\n",
    "        print(f'Prediction corrected:\\n\\tMin:{min(predictions)}\\n\\tMax:{max(predictions)}\\n\\tMean:{np.mean(predictions)}')\n",
    "        lst_prediction.append(predictions)\n",
    "        lst_models_trained.append(model)\n",
    "        i+=1\n",
    "    \n",
    "    df_predictions = pd.DataFrame({\n",
    "        'date': test_dates,\n",
    "        'wp1': lst_prediction[0],\n",
    "        'wp2': lst_prediction[1],\n",
    "        'wp3': lst_prediction[2],\n",
    "        'wp4': lst_prediction[3],\n",
    "        'wp5': lst_prediction[4],\n",
    "        'wp6': lst_prediction[5],        \n",
    "    })\n",
    "    return df_predictions, lst_models_trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = Pipeline([('scaler', MaxAbsScaler()),('xgbr', XGBRegressor(**params_1))])\n",
    "model_2 = Pipeline([('scaler', MaxAbsScaler()),('xgbr', XGBRegressor(**params_2))])\n",
    "model_3 = Pipeline([('scaler', MaxAbsScaler()),('xgbr', XGBRegressor(**params_3))])\n",
    "model_4 = Pipeline([('scaler', MaxAbsScaler()),('xgbr', XGBRegressor(**params_4))])\n",
    "model_5 = Pipeline([('scaler', MaxAbsScaler()),('xgbr', XGBRegressor(**params_5))])\n",
    "model_6 = Pipeline([('scaler', MaxAbsScaler()),('xgbr', XGBRegressor(**params_6))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_1 = XGBRegressor(**params_1)\n",
    "# model_2 = XGBRegressor(**params_2)\n",
    "# model_3 = XGBRegressor(**params_3)\n",
    "# model_4 = XGBRegressor(**params_4)\n",
    "# model_5 = XGBRegressor(**params_5)\n",
    "# model_6 = XGBRegressor(**params_6)\n",
    "\n",
    "lst_models = [model_1, model_2, model_3, model_4, model_5, model_6]\n",
    "lst_X_trains = [X1, X2, X3, X4, X5, X6]\n",
    "lst_y_trains = [y1, y2, y3, y4, y5, y6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_tests = []\n",
    "for test in [test_wp1, test_wp2, test_wp3, test_wp4, test_wp5, test_wp6]:\n",
    "    test = make_prediction_dataset(test)\n",
    "    lst_tests.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------Model 1--------------\n",
      "True:\n",
      "\tMin:0.0\n",
      "\tMax:0.96\n",
      "\tMean:0.2845981952075702\n",
      "Prediction:\n",
      "\tMin:-0.040609680116176605\n",
      "\tMax:0.9584257006645203\n",
      "\tMean:0.2994403839111328\n",
      "Prediction corrected:\n",
      "\tMin:0.0\n",
      "\tMax:0.9584257006645203\n",
      "\tMean:0.299561041407802\n",
      "--------------Model 2--------------\n",
      "True:\n",
      "\tMin:0.0\n",
      "\tMax:0.966\n",
      "\tMean:0.25890153769841273\n",
      "Prediction:\n",
      "\tMin:-0.03859954699873924\n",
      "\tMax:1.0072672367095947\n",
      "\tMean:0.2552209198474884\n",
      "Prediction corrected:\n",
      "\tMin:0.0\n",
      "\tMax:0.966\n",
      "\tMean:0.2553686954124512\n",
      "--------------Model 3--------------\n",
      "True:\n",
      "\tMin:0.0\n",
      "\tMax:0.989\n",
      "\tMean:0.2625247252747253\n",
      "Prediction:\n",
      "\tMin:-0.07822347432374954\n",
      "\tMax:1.0252376794815063\n",
      "\tMean:0.2915489375591278\n",
      "Prediction corrected:\n",
      "\tMin:0.0\n",
      "\tMax:0.989\n",
      "\tMean:0.29178245276974524\n",
      "--------------Model 4--------------\n",
      "True:\n",
      "\tMin:0.0\n",
      "\tMax:0.992\n",
      "\tMean:0.2763637820512821\n",
      "Prediction:\n",
      "\tMin:-0.019250165671110153\n",
      "\tMax:0.9634188413619995\n",
      "\tMean:0.2832432985305786\n",
      "Prediction corrected:\n",
      "\tMin:0.0\n",
      "\tMax:0.9634188413619995\n",
      "\tMean:0.2833424258501441\n",
      "--------------Model 5--------------\n",
      "True:\n",
      "\tMin:0.0\n",
      "\tMax:0.978\n",
      "\tMean:0.32622119200244204\n",
      "Prediction:\n",
      "\tMin:-0.04621139168739319\n",
      "\tMax:1.0799273252487183\n",
      "\tMean:0.33305543661117554\n",
      "Prediction corrected:\n",
      "\tMin:0.0\n",
      "\tMax:0.978\n",
      "\tMean:0.33307137521291136\n",
      "--------------Model 6--------------\n",
      "True:\n",
      "\tMin:0.0\n",
      "\tMax:0.947\n",
      "\tMean:0.2425176472832723\n",
      "Prediction:\n",
      "\tMin:-0.0130529860034585\n",
      "\tMax:0.8685023188591003\n",
      "\tMean:0.2370697557926178\n",
      "Prediction corrected:\n",
      "\tMin:0.0\n",
      "\tMax:0.8685023188591003\n",
      "\tMean:0.23708150108524484\n"
     ]
    }
   ],
   "source": [
    "df_predictions, lst_models_trained = make_submission_file(lst_X_trains, lst_y_trains, lst_tests, lst_models, test_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions.to_csv('Predictions/submission_nb_7_full_absmax-xgboost.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_model = \"Models/XGBOOST/XGBoost-maxabs-wp1-50trials_best.pkl\"\n",
    "with open(pkl_model, 'wb') as file:\n",
    "    pickle.dump(lst_models_trained[0], file)\n",
    "    \n",
    "pkl_model = \"Models/XGBOOST/XGBoost-maxabs-wp2-50trials_best.pkl\"\n",
    "with open(pkl_model, 'wb') as file:\n",
    "    pickle.dump(lst_models_trained[1], file)\n",
    "    \n",
    "pkl_model = \"Models/XGBOOST/XGBoost-maxabs-wp3-50trials_best.pkl\"\n",
    "with open(pkl_model, 'wb') as file:\n",
    "    pickle.dump(lst_models_trained[2], file)\n",
    "\n",
    "pkl_model = \"Models/XGBOOST/XGBoost-maxabs-wp4-50trials_best.pkl\"\n",
    "with open(pkl_model, 'wb') as file:\n",
    "    pickle.dump(lst_models_trained[3], file)\n",
    "    \n",
    "pkl_model = \"Models/XGBOOST/XGBoost-maxabs-wp5-50trials_best.pkl\"\n",
    "with open(pkl_model, 'wb') as file:\n",
    "    pickle.dump(lst_models_trained[4], file)\n",
    "    \n",
    "pkl_model = \"Models/XGBOOST/XGBoost-maxabs-wp6-50trials_best.pkl\"\n",
    "with open(pkl_model, 'wb') as file:\n",
    "    pickle.dump(lst_models_trained[5], file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
